<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Problem Sheet 1 | MATH2750 Introduction to Markov Processes</title>
  <meta name="description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Problem Sheet 1 | MATH2750 Introduction to Markov Processes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://mpaldridge.github.io/math2750/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Problem Sheet 1 | MATH2750 Introduction to Markov Processes" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="S02-random-walk.html"/>
<link rel="next" href="S03-gamblers-ruin.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH2750 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH2750</a><ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-module"><i class="fa fa-check"></i>Organisation of MATH2750</a><ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-computing"><i class="fa fa-check"></i>Computing worksheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#dropin"><i class="fa fa-check"></i>Drop-in sessions</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#team"><i class="fa fa-check"></i>Microsoft Team</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#time"><i class="fa fa-check"></i>Time management</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#exam"><i class="fa fa-check"></i>Exam</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#ask"><i class="fa fa-check"></i>Who should I ask about…?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-content"><i class="fa fa-check"></i>Content of MATH2750</a><ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#prereqs"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#books"><i class="fa fa-check"></i>Books</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#finally"><i class="fa fa-check"></i>And finally…</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Discrete time Markov chains</b></span></li>
<li class="chapter" data-level="1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html"><i class="fa fa-check"></i><b>1</b> Stochastic processes and the Markov property</a><ul>
<li class="chapter" data-level="1.1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#models"><i class="fa fa-check"></i><b>1.1</b> Deterministic and random models</a></li>
<li class="chapter" data-level="1.2" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#stochastic-processes"><i class="fa fa-check"></i><b>1.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="1.3" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#markov-property"><i class="fa fa-check"></i><b>1.3</b> Markov property</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-random-walk.html"><a href="S02-random-walk.html"><i class="fa fa-check"></i><b>2</b> Random walk</a><ul>
<li class="chapter" data-level="2.1" data-path="S02-random-walk.html"><a href="S02-random-walk.html#simple-random-walk"><i class="fa fa-check"></i><b>2.1</b> Simple random walk</a></li>
<li class="chapter" data-level="2.2" data-path="S02-random-walk.html"><a href="S02-random-walk.html#general-random-walks"><i class="fa fa-check"></i><b>2.2</b> General random walks</a></li>
<li class="chapter" data-level="2.3" data-path="S02-random-walk.html"><a href="S02-random-walk.html#exact-distribution"><i class="fa fa-check"></i><b>2.3</b> Exact distribution of the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html"><i class="fa fa-check"></i><b>3</b> Gambler’s ruin</a><ul>
<li class="chapter" data-level="3.1" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-chain"><i class="fa fa-check"></i><b>3.1</b> Gambler’s ruin Markov chain</a></li>
<li class="chapter" data-level="3.2" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-probability"><i class="fa fa-check"></i><b>3.2</b> Probability of ruin</a></li>
<li class="chapter" data-level="3.3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#expected-duration"><i class="fa fa-check"></i><b>3.3</b> Expected duration of the game</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-ldes.html"><a href="S04-ldes.html"><i class="fa fa-check"></i><b>4</b> Linear difference equations</a><ul>
<li class="chapter" data-level="4.1" data-path="S04-ldes.html"><a href="S04-ldes.html#hom-ldes"><i class="fa fa-check"></i><b>4.1</b> Homogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.2" data-path="S04-ldes.html"><a href="S04-ldes.html#ruin-probability-solve"><i class="fa fa-check"></i><b>4.2</b> Probability of ruin for the gambler’s ruin</a></li>
<li class="chapter" data-level="4.3" data-path="S04-ldes.html"><a href="S04-ldes.html#inhom-ldes"><i class="fa fa-check"></i><b>4.3</b> Inhomogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.4" data-path="S04-ldes.html"><a href="S04-ldes.html#duration-solve"><i class="fa fa-check"></i><b>4.4</b> Expected duration for the gambler’s ruin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem sheet 2</a></li>
<li class="chapter" data-level="" data-path="A1.html"><a href="A1.html"><i class="fa fa-check"></i>Assessment 1</a></li>
<li class="chapter" data-level="5" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html"><i class="fa fa-check"></i><b>5</b> Discrete time Markov chains</a><ul>
<li class="chapter" data-level="5.1" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#thmc"><i class="fa fa-check"></i><b>5.1</b> Time homogeneous discrete time Markov chains</a></li>
<li class="chapter" data-level="5.2" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#S05-example"><i class="fa fa-check"></i><b>5.2</b> A two-state example</a></li>
<li class="chapter" data-level="5.3" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#n-step"><i class="fa fa-check"></i><b>5.3</b> <em>n</em>-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-examples.html"><a href="S06-examples.html"><i class="fa fa-check"></i><b>6</b> Examples from actuarial science</a><ul>
<li class="chapter" data-level="6.1" data-path="S06-examples.html"><a href="S06-examples.html#S06-example1"><i class="fa fa-check"></i><b>6.1</b> A simple no-claims discount model</a></li>
<li class="chapter" data-level="6.2" data-path="S06-examples.html"><a href="S06-examples.html#S06-example2"><i class="fa fa-check"></i><b>6.2</b> An accident model with memory</a></li>
<li class="chapter" data-level="6.3" data-path="S06-examples.html"><a href="S06-examples.html#S06-example3"><i class="fa fa-check"></i><b>6.3</b> A no-claims discount model with memory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem sheet 3</a></li>
<li class="chapter" data-level="7" data-path="S07-classes.html"><a href="S07-classes.html"><i class="fa fa-check"></i><b>7</b> Class structure</a><ul>
<li class="chapter" data-level="7.1" data-path="S07-classes.html"><a href="S07-classes.html#comm-classes"><i class="fa fa-check"></i><b>7.1</b> Communicating classes</a></li>
<li class="chapter" data-level="7.2" data-path="S07-classes.html"><a href="S07-classes.html#periodicity"><i class="fa fa-check"></i><b>7.2</b> Periodicity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html"><i class="fa fa-check"></i><b>8</b> Hitting times</a><ul>
<li class="chapter" data-level="8.1" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#hitting-definitions"><i class="fa fa-check"></i><b>8.1</b> Hitting probability and expected hitting time</a></li>
<li class="chapter" data-level="8.2" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-times"><i class="fa fa-check"></i><b>8.2</b> Return times</a></li>
<li class="chapter" data-level="8.3" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-rw"><i class="fa fa-check"></i><b>8.3</b> Hitting and return times for the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem sheet 4</a></li>
<li class="chapter" data-level="9" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html"><i class="fa fa-check"></i><b>9</b> Recurrence and transience</a><ul>
<li class="chapter" data-level="9.1" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-trans-def"><i class="fa fa-check"></i><b>9.1</b> Recurrence and transience of states</a></li>
<li class="chapter" data-level="9.2" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-tran-classes"><i class="fa fa-check"></i><b>9.2</b> Recurrence and transience of classes</a></li>
<li class="chapter" data-level="9.3" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-positive-null"><i class="fa fa-check"></i><b>9.3</b> Positive and null recurrence</a></li>
<li class="chapter" data-level="9.4" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-strong-markov"><i class="fa fa-check"></i><b>9.4</b> Strong Markov property</a></li>
<li class="chapter" data-level="9.5" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-lemma"><i class="fa fa-check"></i><b>9.5</b> A useful lemma</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html"><i class="fa fa-check"></i><b>10</b> Stationary distributions</a><ul>
<li class="chapter" data-level="10.1" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#def-stationary-definition"><i class="fa fa-check"></i><b>10.1</b> Definition</a></li>
<li class="chapter" data-level="10.2" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#find-stationary"><i class="fa fa-check"></i><b>10.2</b> Finding a stationary distribution</a></li>
<li class="chapter" data-level="10.3" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#exist-unique"><i class="fa fa-check"></i><b>10.3</b> Existence and uniqueness</a></li>
<li class="chapter" data-level="10.4" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#stat-proof"><i class="fa fa-check"></i><b>10.4</b> Proof of existence and uniqueness</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem sheet 5</a></li>
<li class="chapter" data-level="11" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html"><i class="fa fa-check"></i><b>11</b> Long-term behaviour of Markov chains</a><ul>
<li class="chapter" data-level="11.1" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#equilibrium"><i class="fa fa-check"></i><b>11.1</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="11.2" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#convergence-examples"><i class="fa fa-check"></i><b>11.2</b> Examples of convergence and non-convergence</a></li>
<li class="chapter" data-level="11.3" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-ergodic"><i class="fa fa-check"></i><b>11.3</b> Ergodic theorem</a></li>
<li class="chapter" data-level="11.4" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-proofs"><i class="fa fa-check"></i><b>11.4</b> Proofs of the limit and ergodic theorems</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S11-revision-i.html"><a href="S11-revision-i.html"><i class="fa fa-check"></i><b>12</b> Revision of Part 1: Discrete time Markov chains</a><ul>
<li class="chapter" data-level="12.1" data-path="S11-revision-i.html"><a href="S11-revision-i.html#S12-revision"><i class="fa fa-check"></i><b>12.1</b> Things to do</a></li>
<li class="chapter" data-level="12.2" data-path="S11-revision-i.html"><a href="S11-revision-i.html#S12-summary-i"><i class="fa fa-check"></i><b>12.2</b> Summary of Part 1</a></li>
</ul></li>
<li class="part"><span><b>Part II: Continuous time Markov jump processes</b></span></li>
<li class="chapter" data-level="13" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html"><i class="fa fa-check"></i><b>13</b> Poisson process with Poisson increments</a><ul>
<li class="chapter" data-level="13.1" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-dist"><i class="fa fa-check"></i><b>13.1</b> Poisson distribution</a></li>
<li class="chapter" data-level="13.2" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-def-poisson"><i class="fa fa-check"></i><b>13.2</b> Definition 1: Poisson increments</a></li>
<li class="chapter" data-level="13.3" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#summed-marked"><i class="fa fa-check"></i><b>13.3</b> Summed and marked Poisson processes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html"><i class="fa fa-check"></i><b>14</b> Poisson process with exponential holding times</a><ul>
<li class="chapter" data-level="14.1" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#exponential"><i class="fa fa-check"></i><b>14.1</b> Exponential distribution</a></li>
<li class="chapter" data-level="14.2" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#definition-2-exponential-holding-times"><i class="fa fa-check"></i><b>14.2</b> Definition 2: exponential holding times</a></li>
<li class="chapter" data-level="14.3" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#cont-markov"><i class="fa fa-check"></i><b>14.3</b> Markov property in continuous time</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="S15-poisson-exponential.html"><a href="S15-poisson-exponential.html"><i class="fa fa-check"></i><b>15</b> Poisson process in infinitesimal time periods</a><ul>
<li class="chapter" data-level="15.1" data-path="S15-poisson-exponential.html"><a href="S15-poisson-exponential.html#infinitesimal"><i class="fa fa-check"></i><b>15.1</b> Definition 3: increments in infinitesimal time</a></li>
<li class="chapter" data-level="15.2" data-path="S15-poisson-exponential.html"><a href="S15-poisson-exponential.html#sum2"><i class="fa fa-check"></i><b>15.2</b> Example: sum of two Poisson processes</a></li>
<li class="chapter" data-level="15.3" data-path="S15-poisson-exponential.html"><a href="S15-poisson-exponential.html#forward"><i class="fa fa-check"></i><b>15.3</b> Forward equations and proof of equivalence</a></li>
</ul></li>
<li class="divider"></li>
<li></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2750 Introduction to Markov Processes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="P01" class="section level1 unnumbered">
<h1>Problem Sheet 1</h1>
<!--
<style>
.fold-btn { 
  float: right; 
  margin: -12px 0 0 0;
}
</style>

<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".myanswers");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Show solution</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");  // if the text equals "Fold", change it to "Unfold"or else to "Fold" 
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>


<style>
.myanswers { 
/* display: none; */
}
</style>
-->
<div class="mysummary">
<p>You should attempt all these questions and write up your solutions in advance of your workshop in week 2 (Monday 1 or Tuesday 2 February) where the answers will be discussed.</p>
</div>
<div class="myq">
<p><strong>1.</strong> When designing a model for a quantity that changes over time, one has many decisions to make:</p>
<ul>
<li>Discrete or continuous state space?</li>
<li>Discrete or continuous index set for time?</li>
<li>Deterministic or stochastic model?</li>
<li>If a stochastic model is chosen, is it reasonable to assume that the Markov property holds?</li>
</ul>
<p>What would you decide for the following scenarios:</p>
<div class="subq">
<p><strong>(a)</strong> The percentage of US voters with a positive opinion of Donald Trump in the Gallup weekly tracking poll.</p>
</div>
<div class="subq">
<p><strong>(b)</strong> The number of points won by a football league club throughout the season.</p>
</div>
<div class="subq">
<p><strong>(c)</strong> The temperature of a bowl of water placed in an oven.</p>
</div>
<div class="subq">
<p><strong>(d)</strong> The number of people inside the Chemistry building.</p>
<div class="myanswers">
<p><em>Suggestions.</em> This question is meant to inspire discussion, so there are not necessarily right and wrong answers. If I were designing the models, however, my choices might be these:</p>
<p><strong>(a)</strong> Discrete space if percentages are given to nearest 1%, otherwise continuous; discrete time (weekly); stochastic; the Markov property might be appropriate, perhaps using some sort of random walk.</p>
<p><strong>(b)</strong> Discrete space (number of points); discrete time (update after each game); stochastic; the Markov property might be appropriate, depending on if you think teams can have non-Markovian “winning streaks” (or losing streaks) that don’t reflect underlying performance.</p>
<p><strong>(c)</strong> Continuous space (temperature); continuous time; if the oven is reliable and the experiment carried out carefully, a deterministic model might be sufficient.</p>
<p><strong>(d)</strong> Discrete space (number of people); continuous time; stochastic; Markov property might not be appropriate due to `bursts’ of people leaving during fire drills or lectures finishing early.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>2.</strong> A fair six-sided dice is rolled twice, resulting in the
values <span class="math inline">\(X_1, X_2 \in \{1, 2, \ldots, 6\}\)</span>. Let <span class="math inline">\(Y = X_1 + X_2\)</span> be the total score.
Calculate:</p>
<div class="subq">
<p><strong>(a)</strong> the probability <span class="math inline">\(\mathbb P(Y = 10)\)</span>;</p>
<div class="myanswers">
<p><em>Solution.</em> The following table illustrates the possible outcomes <span class="math inline">\(Y\)</span> of the experiment. Each cell of the table is an equally probable outcome.</p>
<p><img src="math2750_files/figure-html/dice-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>There are 3 possible ways to get <span class="math inline">\(Y=10\)</span> (the grey cells in the table) out of the <span class="math inline">\(36\)</span> possible outcomes, so we have <span class="math inline">\(\mathbb P(Y = 10) = 3/36 = 1/12\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> the conditional probability <span class="math inline">\(\mathbb P(Y=10 \mid X_1=x)\)</span> for <span class="math inline">\(x=1, 2, \ldots, 6\)</span>;</p>
<div class="myanswers">
<p><em>Solution.</em> Conditioning on <span class="math inline">\(X_1 = x\)</span> means restricting our attention only to column <span class="math inline">\(x\)</span> of the table. Each column has <span class="math inline">\(6\)</span> equally probably cells. For <span class="math inline">\(x=1,2,3\)</span>, none of the entries equal <span class="math inline">\(10\)</span>, so <span class="math inline">\(\mathbb P(Y=10 \mid X_1=x) = 0/6 = 0\)</span>. For each of <span class="math inline">\(x=4,5,6\)</span>, one of the entries equals <span class="math inline">\(10\)</span>, so <span class="math inline">\(\mathbb P(Y=10 \mid X_1=x) = 1/6\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> the conditional probability <span class="math inline">\(\mathbb P(X_1=x \mid Y=10)\)</span> for <span class="math inline">\(x=1, 2, \ldots, 6\)</span>.</p>
<div class="myanswers">
<p><em>Solution.</em> Conditioning on <span class="math inline">\(Y =10\)</span> means restricting our attention only to the <span class="math inline">\(3\)</span> shaded cells, which are each equally likely. For <span class="math inline">\(x=1,2,3\)</span>, none of the shaded cells are in column <span class="math inline">\(x\)</span>, so <span class="math inline">\(\mathbb P(X_1=x \mid Y=10) = 0/3 = 0\)</span>. For each of <span class="math inline">\(x=4,5,6\)</span>, one of the shaded cells is in column <span class="math inline">\(x\)</span>, so <span class="math inline">\(\mathbb P(X_1=x \mid Y=10) = 1/3\)</span>.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>3.</strong> Let <span class="math inline">\((X_n)\)</span> be a simple random walk starting from <span class="math inline">\(X_0 = 0\)</span> and that at each step goes up one with probability <span class="math inline">\(p\)</span> or down one with probability <span class="math inline">\(q = 1-p\)</span>. What are:</p>
<div class="subq">
<p><strong>(a)</strong> <span class="math inline">\(\mathbb P(X_5 = 3)\)</span>,</p>
<div class="myanswers">
<p><em>Solution.</em> To get <span class="math inline">\(X_5 = 3\)</span>, we must take <span class="math inline">\(4\)</span> steps up and <span class="math inline">\(1\)</span> step down. The down step can be at any of the <span class="math inline">\(5\)</span> time steps. Therefore we have <span class="math inline">\(\mathbb P(X_5 = 3) = 5p^4q\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> <span class="math inline">\(\mathbb P(X_5 = 3 \mid X_2 = 2)\)</span>,</p>
<div class="myanswers">
<p><em>Solution.</em> Once we’re at <span class="math inline">\(X_2 = 2\)</span>, we must take <span class="math inline">\(2\)</span> steps up and <span class="math inline">\(1\)</span> step down over the next <span class="math inline">\(3\)</span> time steps. So <span class="math inline">\(\mathbb P(X_5 = 3 \mid X_2 = 2) = 3p^2q\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> <span class="math inline">\(\mathbb P(X_n = n-2)\)</span>,</p>
<div class="myanswers">
<p><em>Solution.</em> This requires <span class="math inline">\(n-1\)</span> steps up and <span class="math inline">\(1\)</span> step down, and the down step can be at any of the <span class="math inline">\(n\)</span> time steps. So <span class="math inline">\(\mathbb P(X_n = n-2) = np^{n-1}q\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(d)</strong> <span class="math inline">\(\mathbb E X_4\)</span>,</p>
<div class="myanswers">
<p><em>Solution.</em> The increments <span class="math inline">\(Z_n = X_n - X_{n-1}\)</span> have expectation <span class="math inline">\(1p + (-1)q = p - q\)</span>, so <span class="math inline">\(\mathbb E X_4 = 4(p-q)\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(e)</strong> <span class="math inline">\(\mathbb E(X_6 \mid X_4 = 2)\)</span>,</p>
<div class="myanswers">
<p><em>Solution.</em> We are already at 2, then another two increments will take us up <span class="math inline">\(2(p-q)\)</span> on average. Therefore <span class="math inline">\(\mathbb E(X_6 \mid X_4 = 2) = 2 + 2(p-q)\)</span>.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>4.</strong> The price <span class="math inline">\(X_n\)</span> of a stock at the close of day <span class="math inline">\(n\)</span> is modelled as a Gaussian random walk, where the increments <span class="math inline">\((Z_n)\)</span> have a normal distribution <span class="math inline">\(Z_n \sim \text{N}(\mu, \sigma^2)\)</span>. The model assumes a drift of <span class="math inline">\(\mu = 0.7\)</span> and a volatility of <span class="math inline">\(\sigma = 2.2\)</span>. The initial price is <span class="math inline">\(X_0 = 42.3\)</span>.</p>
<div class="subq">
<p><strong>(a)</strong> Calculate the mean and variance of the price of the stock at the close of day <span class="math inline">\(5\)</span>.</p>
<div class="myanswers">
<p><em>Solution.</em> The mean and variance are
<span class="math display">\[\begin{gather*}
  \mathbb EX_5 = \mathbb E X_0 + n \mathbb E Z_1 = 42.3 + 5 \cdot 0.7 = 45.8 , \\
  \operatorname{Var}X_5 = \operatorname{Var}X_0 + n \operatorname{Var}Z_1 = 0 + 5 (2.2)^2 = 24.2 .
  \end{gather*}\]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> Give a 95% prediction interval for the price at the close of day 5. (You might find it useful to recall that, if <span class="math inline">\(W \sim \text{N}(0,1)\)</span> is a standard normal random variable, then <span class="math inline">\(\mathbb P(W \leq 1.96) = 0.975\)</span>.)</p>
<div class="myanswers">
<p><em>Solution.</em> Note that <span class="math inline">\(X_5\)</span> itself is normally distributed, so <span class="math inline">\(X_5 \sim \text{N}(45.8,24.2)\)</span>. The 95% prediction interval for a normal distribution <span class="math inline">\(\text{N}(\mu, \sigma^2)\)</span> is <span class="math inline">\((\mu - 1.96\sigma, \mu + 1.96\sigma)\)</span>, so the prediction interval for <span class="math inline">\(X_5\)</span> is
<span class="math display">\[ \big(45.8 - 1.96\sqrt{24.2},  45.8 + 1.96\sqrt{24.2}\big) = (36.16, 55.44) . \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> After day 4, the prices at the end of each of the first four days have been recorded as <span class="math inline">\(X_1 = 44.4, X_2 = 44.0, X_3 = 47.1, X_4 = 47.8\)</span>. Update your prediction interval for the price at the close of day 5, and comment on how it differs from the earlier prediction interval.</p>
<div class="myanswers">
<p><em>Solution.</em> By the Markov property, <span class="math inline">\(X_5\)</span> depends on <span class="math inline">\(X_4\)</span>, but given <span class="math inline">\(X_4\)</span> does not depend on the other values, which we can therefore ignore. Since <span class="math inline">\(X_5 = X_4 + Z_5\)</span>, we have
<span class="math display">\[\begin{gather*}
  \mathbb E(X_5 \mid X_4) = X_4 + \mathbb E Z_5 = 47.8 + 0.7 = 48.5 \\
  \operatorname{Var}(X_5 \mid X_4) = 0 + \operatorname{Var}Z_5 = 0 + (2.2)^2 = 4.84.
  \end{gather*}\]</span>
The desired prediction interval is
<span class="math display">\[ \big(48.5 - 1.96\sqrt{4.84},  48.5+ 1.96\sqrt{4.84}\big) = (44.19, 52.81) . \]</span>
Compared to before, the centre of the prediction interval is slightly higher, because the stock has outperformed expectations so far, and the interval is much narrower, because as we get closer to day 5 we become less uncertain.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>5.</strong> A gambler decides to model her total winnings as a simple random walk starting from <span class="math inline">\(X_0 = 0\)</span> that at each time goes up one with probability <span class="math inline">\(p\)</span> and down one with probability <span class="math inline">\(1-p\)</span>, but where <span class="math inline">\(p\)</span> is unknown. The first <span class="math inline">\(10\)</span> recordings, <span class="math inline">\(X_1\)</span> to <span class="math inline">\(X_{10}\)</span>, are
<span class="math display">\[ (1, 2, 1, 2, 3, 4, 5, 6, 5, 6) . \]</span></p>
<div class="subq">
<p><strong>(a)</strong> What would you guess for the value of <span class="math inline">\(p\)</span>, given this data?</p>
<div class="myanswers">
<p><em>Solution.</em> In <span class="math inline">\(10\)</span> time steps, the process went up <span class="math inline">\(k = 8\)</span> times and down <span class="math inline">\(n - k = 2\)</span> times. So it seems reasonable to guess that <span class="math inline">\(p\)</span> has the value <span class="math inline">\(\hat p = 8/10 = 0.8\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> More generally, how would you estimate <span class="math inline">\(p\)</span> from the data <span class="math inline">\(X_0 = 0, X_1 = x_1, X_2 = x_2, \dots, X_n = x_n\)</span>?</p>
<div class="myanswers">
<p><em>Solution.</em> We will estimate <span class="math inline">\(\hat p = k/n\)</span>, where <span class="math inline">\(k\)</span> is the number of upward steps. We saw in lectures that <span class="math inline">\(k = (n + x_n)/2\)</span>, so our estimate is
<span class="math display">\[ \hat p = \frac{n + x_n}{2n} = \frac12\ + \frac{x_n}{2n} . \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> Show that your estimate is in fact the maximum likelihood estimate of <span class="math inline">\(p\)</span>.</p>
<div class="myanswers">
<p><em>Solution.</em> You could answer this question by using what you know about maximum likelihood estimation for the binomial distribution from MATH1712, but we’ll reason from first principles here.</p>
<p>If we let <span class="math inline">\(k\)</span> be the number of upward steps, then the likelihood is
<span class="math display">\[ f(\mathbf x; p) = p^{k}(1-p)^{n-k} , \]</span>
making the the log-likelihood
<span class="math display">\[ \ell(\mathbf x; p) = \ln f(\mathbf x; p) = k \ln p + (n-k)\ln(1-p) .\]</span>
We maximise this by differentiating and setting equal to <span class="math inline">\(0\)</span>. The derivative is
<span class="math display">\[ \frac{\text{d}}{\text{d}p} \ell(\mathbf x; p) = \frac kp - \frac{n-k}{1-p} ,\]</span>
so the maximum likelihood estimate <span class="math inline">\(\hat p\)</span> satisfies
<span class="math display">\[ 0 = \frac k{\hat p} - \frac{n-k}{1-\hat p} . \]</span>
Solving this by clearing denominators we get
<span class="math display">\[ 0 = (k - k\hat p) - (n\hat p - k\hat p) = k - n \hat p , \]</span>
and rearranging gives <span class="math inline">\(\hat p = k/n\)</span> as desired.</p>
</div>
</div>
</div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="S02-random-walk.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="S03-gamblers-ruin.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math2750.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

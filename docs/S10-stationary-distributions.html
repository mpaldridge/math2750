<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 10 Stationary distributions | MATH2750 Introduction to Markov Processes</title>
  <meta name="description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 10 Stationary distributions | MATH2750 Introduction to Markov Processes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 10 Stationary distributions | MATH2750 Introduction to Markov Processes" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="S09-recurrence-transience.html"/>
<link rel="next" href="P05.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH2750 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH2750</a><ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-module"><i class="fa fa-check"></i>Organisation of MATH2750</a><ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-assessments"><i class="fa fa-check"></i>Assessments</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-computing"><i class="fa fa-check"></i>Computing worksheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#office"><i class="fa fa-check"></i>Drop-in sessions</a></li>
<li class="chapter" data-level="0.0.1" data-path="S00-about.html"><a href="S00-about.html#discussion-board"><i class="fa fa-check"></i><b>0.0.1</b> Discussion board</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-time"><i class="fa fa-check"></i>Time management</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-exam"><i class="fa fa-check"></i>Exam</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-content"><i class="fa fa-check"></i>Content of MATH2750</a><ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-prereqs"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-books"><i class="fa fa-check"></i>Books</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#S00-finally"><i class="fa fa-check"></i>And finally…</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Discrete time Markov chains</b></span></li>
<li class="chapter" data-level="1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html"><i class="fa fa-check"></i><b>1</b> Stochastic processes and the Markov property</a><ul>
<li class="chapter" data-level="1.1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#models"><i class="fa fa-check"></i><b>1.1</b> Deterministic and random models</a></li>
<li class="chapter" data-level="1.2" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#stochastic-processes"><i class="fa fa-check"></i><b>1.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="1.3" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#markov-property"><i class="fa fa-check"></i><b>1.3</b> Markov property</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-random-walk.html"><a href="S02-random-walk.html"><i class="fa fa-check"></i><b>2</b> Random walk</a><ul>
<li class="chapter" data-level="2.1" data-path="S02-random-walk.html"><a href="S02-random-walk.html#simple-random-walk"><i class="fa fa-check"></i><b>2.1</b> Simple random walk</a></li>
<li class="chapter" data-level="2.2" data-path="S02-random-walk.html"><a href="S02-random-walk.html#general-random-walks"><i class="fa fa-check"></i><b>2.2</b> General random walks</a></li>
<li class="chapter" data-level="2.3" data-path="S02-random-walk.html"><a href="S02-random-walk.html#exact-distribution"><i class="fa fa-check"></i><b>2.3</b> Exact distribution of the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html"><i class="fa fa-check"></i><b>3</b> Gambler’s ruin</a><ul>
<li class="chapter" data-level="3.1" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-chain"><i class="fa fa-check"></i><b>3.1</b> Gambler’s ruin Markov chain</a></li>
<li class="chapter" data-level="3.2" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-probability"><i class="fa fa-check"></i><b>3.2</b> Probability of ruin</a></li>
<li class="chapter" data-level="3.3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#expected-duration"><i class="fa fa-check"></i><b>3.3</b> Expected duration of the game</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-ldes.html"><a href="S04-ldes.html"><i class="fa fa-check"></i><b>4</b> Linear difference equations</a><ul>
<li class="chapter" data-level="4.1" data-path="S04-ldes.html"><a href="S04-ldes.html#hom-ldes"><i class="fa fa-check"></i><b>4.1</b> Homogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.2" data-path="S04-ldes.html"><a href="S04-ldes.html#ruin-probability-solve"><i class="fa fa-check"></i><b>4.2</b> Probability of ruin for the gambler’s ruin</a></li>
<li class="chapter" data-level="4.3" data-path="S04-ldes.html"><a href="S04-ldes.html#inhom-ldes"><i class="fa fa-check"></i><b>4.3</b> Inhomogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.4" data-path="S04-ldes.html"><a href="S04-ldes.html#duration-solve"><i class="fa fa-check"></i><b>4.4</b> Expected duration for the gambler’s ruin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem sheet 2</a></li>
<li class="chapter" data-level="" data-path="A1.html"><a href="A1.html"><i class="fa fa-check"></i>Assessment 1</a></li>
<li class="chapter" data-level="5" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html"><i class="fa fa-check"></i><b>5</b> Discrete time Markov chains</a><ul>
<li class="chapter" data-level="5.1" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#thmc"><i class="fa fa-check"></i><b>5.1</b> Time homogeneous discrete time Markov chains</a></li>
<li class="chapter" data-level="5.2" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#S05-example"><i class="fa fa-check"></i><b>5.2</b> A two-state example</a></li>
<li class="chapter" data-level="5.3" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#n-step"><i class="fa fa-check"></i><b>5.3</b> <em>n</em>-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-examples.html"><a href="S06-examples.html"><i class="fa fa-check"></i><b>6</b> Examples from actuarial science</a><ul>
<li class="chapter" data-level="6.1" data-path="S06-examples.html"><a href="S06-examples.html#S06-example1"><i class="fa fa-check"></i><b>6.1</b> A simple no-claims discount model</a></li>
<li class="chapter" data-level="6.2" data-path="S06-examples.html"><a href="S06-examples.html#S06-example2"><i class="fa fa-check"></i><b>6.2</b> An accident model with memory</a></li>
<li class="chapter" data-level="6.3" data-path="S06-examples.html"><a href="S06-examples.html#S06-example3"><i class="fa fa-check"></i><b>6.3</b> A no-claims discount model with memory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem sheet 3</a></li>
<li class="chapter" data-level="7" data-path="S07-classes.html"><a href="S07-classes.html"><i class="fa fa-check"></i><b>7</b> Class structure</a><ul>
<li class="chapter" data-level="7.1" data-path="S07-classes.html"><a href="S07-classes.html#comm-classes"><i class="fa fa-check"></i><b>7.1</b> Communicating classes</a></li>
<li class="chapter" data-level="7.2" data-path="S07-classes.html"><a href="S07-classes.html#periodicity"><i class="fa fa-check"></i><b>7.2</b> Periodicity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html"><i class="fa fa-check"></i><b>8</b> Hitting times</a><ul>
<li class="chapter" data-level="8.1" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#hitting-definitions"><i class="fa fa-check"></i><b>8.1</b> Hitting probability and expected hitting time</a></li>
<li class="chapter" data-level="8.2" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-times"><i class="fa fa-check"></i><b>8.2</b> Return times</a></li>
<li class="chapter" data-level="8.3" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-rw"><i class="fa fa-check"></i><b>8.3</b> Hitting and return times for the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem sheet 4</a></li>
<li class="chapter" data-level="9" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html"><i class="fa fa-check"></i><b>9</b> Recurrence and transience</a><ul>
<li class="chapter" data-level="9.1" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-trans-def"><i class="fa fa-check"></i><b>9.1</b> Recurrence and transience of states</a></li>
<li class="chapter" data-level="9.2" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-tran-classes"><i class="fa fa-check"></i><b>9.2</b> Recurrence and transience of classes</a></li>
<li class="chapter" data-level="9.3" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-positive-null"><i class="fa fa-check"></i><b>9.3</b> Positive and null recurrence</a></li>
<li class="chapter" data-level="9.4" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-strong-markov"><i class="fa fa-check"></i><b>9.4</b> Strong Markov property</a></li>
<li class="chapter" data-level="9.5" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-lemma"><i class="fa fa-check"></i><b>9.5</b> A useful lemma</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html"><i class="fa fa-check"></i><b>10</b> Stationary distributions</a><ul>
<li class="chapter" data-level="10.1" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#definition-def-stationary-definition"><i class="fa fa-check"></i><b>10.1</b> Definition {def-stationary-definition}</a></li>
<li class="chapter" data-level="10.2" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#find-stationary"><i class="fa fa-check"></i><b>10.2</b> Finding a stationary distribution</a></li>
<li class="chapter" data-level="10.3" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#exist-unique"><i class="fa fa-check"></i><b>10.3</b> Existence and uniqueness</a></li>
<li class="chapter" data-level="10.4" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#stat-proof"><i class="fa fa-check"></i><b>10.4</b> Proof of existence and uniqueness</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem sheet 5</a></li>
<li class="chapter" data-level="11" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html"><i class="fa fa-check"></i><b>11</b> Long-term behaviour of Markov chains</a><ul>
<li class="chapter" data-level="11.1" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#equilibrium"><i class="fa fa-check"></i><b>11.1</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="11.2" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#convergence-examples"><i class="fa fa-check"></i><b>11.2</b> Examples of convergence and non-convergence</a></li>
<li class="chapter" data-level="11.3" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-ergodic"><i class="fa fa-check"></i><b>11.3</b> Ergodic theorem</a></li>
<li class="chapter" data-level="11.4" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-proofs"><i class="fa fa-check"></i><b>11.4</b> Proofs of the limit and ergodic theorems</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S11-revision-i.html"><a href="S11-revision-i.html"><i class="fa fa-check"></i><b>12</b> Revision of Part 1: Discrete time Markov chains</a><ul>
<li class="chapter" data-level="12.1" data-path="S11-revision-i.html"><a href="S11-revision-i.html#S12-revision"><i class="fa fa-check"></i><b>12.1</b> Things to do</a></li>
<li class="chapter" data-level="12.2" data-path="S11-revision-i.html"><a href="S11-revision-i.html#S12-summary-i"><i class="fa fa-check"></i><b>12.2</b> Summary of Part 1</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2750 Introduction to Markov Processes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S10-stationary-distributions" class="section level1">
<h1><span class="header-section-number">Section 10</span> Stationary distributions</h1>
<div class="mysummary">
<ul>
<li>Stationary distributions and how to find them</li>
<li>Conditions for existence and uniqueness of the stationary distribution</li>
</ul>
</div>
<div id="definition-def-stationary-definition" class="section level2">
<h2><span class="header-section-number">10.1</span> Definition {def-stationary-definition}</h2>
<p>Consider <a href="S05-markov-chains.html#S05-example">the two-state “broken printer” Markov chain from Lecture 5</a>.</p>
<p><img src="math2750_files/figure-html/twostate2-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Suppose we start the chain from the initial distribution
<span class="math display">\[ \lambda_0 = \mathbb P(X_0 = 0) = \frac{\beta}{\alpha+\beta} \qquad \lambda_1 = \mathbb P(X_0 = 1) = \frac{\alpha}{\alpha+\beta} . \]</span>
(You may recognise this from <a href="P03.html#P03">Question 1 on Problem Sheet 3</a>.) What’s the distribution after step 1? By conditioning on the initial state, we have
<span class="math display">\[\begin{align*}
  \mathbb P(X_1 = 0) &amp;= \lambda_0 p_{00} + \lambda_1 p_{10} = \frac{\beta}{\alpha+\beta}(1-\alpha) + \frac{\alpha}{\alpha+\beta}\beta = \frac{\beta}{\alpha+\beta} ,\\
  \mathbb P(X_1 = 1) &amp;= \lambda_0 p_{01} + \lambda_1 p_{11} = \frac{\beta}{\alpha+\beta}\alpha + \frac{\alpha}{\alpha+\beta}(1-\beta) = \frac{\alpha}{\alpha+\beta} .
\end{align*}\]</span>
So we’re still in the same distribution we started in. By repeating the same calculation, we’re still going to be in this distribution after step 2, and step 3, and forever.</p>
<p>More generally, if we start from a state given by a distribution <span class="math inline">\(\boldsymbol \pi = (\pi_i)\)</span>, then after step 1 the probability we’re in state <span class="math inline">\(j\)</span> is <span class="math inline">\(\sum_i \pi_i p_{ij}\)</span>. So if <span class="math inline">\(\pi_j = \sum_i \pi_i p_{ij}\)</span>, we stay in this distribution forever. In matrix form, this is <span class="math inline">\(\boldsymbol \pi = \boldsymbol \pi\mathsf P\)</span>. (Remember that <span class="math inline">\(\boldsymbol \pi\)</span> is a <em>row</em> vector.) We call such a distribution a stationary distribution.</p>
<div class="definition">
<p><span id="def:unlabeled-div-12" class="definition"><strong>Definition 10.1  </strong></span>Let <span class="math inline">\((X_n)\)</span> be a Markov chain on a state space <span class="math inline">\(\mathcal S\)</span> with transition matrix <span class="math inline">\(\mathsf P\)</span>.
Let <span class="math inline">\(\boldsymbol \pi = (\pi_i)\)</span> be a distribution on <span class="math inline">\(\mathcal S\)</span>, in that <span class="math inline">\(\pi_i \geq 0\)</span> for all <span class="math inline">\(i \in \mathcal S\)</span> and <span class="math inline">\(\sum_{i \in \mathcal S} \pi_i = 1\)</span>. We call <span class="math inline">\(\boldsymbol \pi\)</span> a <strong>stationary distribution</strong> if
<span class="math display">\[ \pi_j = \sum_{i\in \mathcal S} \pi_i p_{ij} \quad \text{for all $j \in \mathcal S$,} \]</span>
or, equivalently, if <span class="math inline">\(\boldsymbol \pi = \boldsymbol \pi\mathsf P\)</span>.</p>
</div>
<p>Note that we’re saying the <em>distribution</em> <span class="math inline">\(\mathbb P(X_n = i)\)</span> stays the same; the Markov chain <span class="math inline">\((X_n)\)</span> itself will keep moving. One way to think is that if we started off a thousand Markov chains, choosing each starting position to be <span class="math inline">\(i\)</span> with probability <span class="math inline">\(\pi_i\)</span>, then (roughly) <span class="math inline">\(1000 \pi_j\)</span> of them would be in state <span class="math inline">\(j\)</span> at any time in the future – but not necessarily the same ones each time.</p>
</div>
<div id="find-stationary" class="section level2">
<h2><span class="header-section-number">10.2</span> Finding a stationary distribution</h2>
<p>Let’s try an example. Consider <a href="S06-examples.html#S06-example1">the no-claims discount Markov chain from Lecture 6</a> with state space <span class="math inline">\(\mathcal S=\{1,2,3\}\)</span> and transition matrix
<span class="math display">\[ \mathsf P =\begin{pmatrix}
    \tfrac14 &amp;\tfrac34 &amp; 0\\
    \tfrac14 &amp;0 &amp; \tfrac34\\
    0 &amp;\tfrac14 &amp; \tfrac34\\
    \end{pmatrix} .\]</span></p>
<p>We want to find a stationary distribution <span class="math inline">\(\boldsymbol \pi\)</span>, which must solve the equation <span class="math inline">\(\boldsymbol \pi =\boldsymbol \pi\mathsf P\)</span>, which is
<span class="math display">\[ \begin{pmatrix} \pi_1 &amp; \pi_2 &amp; \pi_3 \end{pmatrix}  = \begin{pmatrix} \pi_1 &amp; \pi_2 &amp; \pi_3 \end{pmatrix}  \begin{pmatrix}
    \tfrac14 &amp;\tfrac34 &amp; 0\\
    \tfrac14 &amp;0 &amp; \tfrac34\\
    0 &amp;\tfrac14 &amp; \tfrac34\\
    \end{pmatrix} .\]</span></p>
<p>Writing out the equations coordinate at a time, we have
<span class="math display">\[\begin{align*}
    \pi_1 &amp;= \tfrac14\pi_1+\tfrac14\pi_2 , \\
    \pi_2 &amp;= \tfrac34\pi_1+\tfrac14\pi_3 , \\
    \pi_3 &amp;= \tfrac34\pi_2+\tfrac34\pi_3 . 
    \end{align*}\]</span>
Since <span class="math inline">\(\boldsymbol\pi\)</span> must be a distribution, we also have the “normalising condition”
<span class="math display">\[ \pi_1+\pi_2+\pi_3=1 . \]</span></p>
<p>The way to solve these equations is first to solve for all the variables <span class="math inline">\(\pi_i\)</span> in terms of a convenient <span class="math inline">\(\pi_{j}\)</span> (called the “working variable”) and then substitute all of these expressions into the normalising condition to find a value for <span class="math inline">\(\pi_{j}\)</span>.</p>
<p>Let’s choose <span class="math inline">\(\pi_2\)</span> as our working variable. It turns out that <span class="math inline">\(\boldsymbol\pi = \boldsymbol\pi \mathsf{P}\)</span> always gives one more equation than we actually need, so we can discard one of them for free. Let’s get rid of the second equation, and the solve the first and third equations in terms of our working variable <span class="math inline">\(\pi_2\)</span>, to get
<span class="math display" id="eq:statt">\[\begin{equation}
\pi_1=\tfrac13\pi_2 \qquad \pi_3=3\pi_2 . \tag{10.1}
\end{equation}\]</span></p>
<p>Now let’s turn to the normalising condition. That gives
<span class="math display">\[ \pi_1+\pi_2+\pi_3 = \tfrac13\pi_2+\pi_2+3\pi_2 = \tfrac{13}{3} \pi_2 = 1 .\]</span>
So the working variable is solved to be <span class="math inline">\(\pi_2 = \frac{3}{13}\)</span>. Substituting this back into <a href="S10-stationary-distributions.html#eq:statt">(10.1)</a>, we have <span class="math inline">\(\pi_1=\tfrac13\pi_2 = \frac{1}{13}\)</span> and <span class="math inline">\(\pi_3=3\pi_2 = \frac{9}{13}\)</span>. So the full solution is
<span class="math display">\[ \boldsymbol \pi = (\pi_1\quad \pi_2\quad \pi_3) = \left(\tfrac{1}{13}\quad \tfrac{3}{13}\quad\tfrac{9}{13}\right). \]</span></p>
<p>The method we used here can be summarised as follows:</p>
<ol style="list-style-type: decimal">
<li>Write out <span class="math inline">\(\boldsymbol \pi = \boldsymbol \pi\mathsf P\)</span> coordinate by coordinate. Discard one of the equations.</li>
<li>Select one of the <span class="math inline">\(\pi_i\)</span> as a working variable and treat it as a parameter. Solve the equations in terms of the working variable.</li>
<li>Substitute the solution into the normalising condition to find the working variable, and hence the full solution.</li>
</ol>
<p>It can be good practice to use the equation discarded earlier to check that the calculated solution is indeed correct.</p>
<p>One extra example for further practice and to show how you should present your solutions to such problems:</p>
<div class="example">
<p><span id="exm:stationary-1" class="example"><strong>Example 10.1  </strong></span><em>Consider a Markov chain on state space <span class="math inline">\(\mathcal S = \{1,2,3\}\)</span> with transition matrix</em>
<span class="math display">\[ \mathsf P = \begin{pmatrix} \tfrac12 &amp; \tfrac14&amp; \frac14 \\
                   \tfrac14&amp; \frac12&amp; \frac14 \\
                   0       &amp; \frac14 &amp; \frac34 \end{pmatrix} . \]</span>
<em>Find a stationary distribution for this Markov chain.</em></p>
<p><em>Step 1.</em> Writing out <span class="math inline">\(\boldsymbol \pi = \boldsymbol \pi\mathsf P\)</span> coordinate-wise, we have
<span class="math display">\[\begin{align*}
\pi_1 &amp;= \tfrac12 \pi_1 + \tfrac14\pi_2 \\
\pi_2 &amp;= \tfrac14\pi_1 + \tfrac12\pi_2 + \tfrac14\pi_3 \\
\pi_3 &amp;= \tfrac14\pi_1 + \tfrac14\pi_2 + \tfrac34\pi_3 .
\end{align*}\]</span>
We choose to discard the third equation.</p>
<p><em>Step 2.</em> We choose <span class="math inline">\(\pi_1\)</span> as our working variable. From the first equation we get <span class="math inline">\(\pi_2 = 2\pi_1\)</span>. From the second equation we get <span class="math inline">\(\pi_3 = 2\pi_2 - \pi_1\)</span>, and substituting the previous <span class="math inline">\(\pi_2 = 2\pi_1\)</span> into this, we get <span class="math inline">\(\pi_3 = 3\pi_1\)</span>.</p>
<p><em>Step 3.</em> The normalising condition is
<span class="math display">\[ \pi_1 + \pi_2 + \pi_3 = \pi_1 + 2\pi_1 + 3\pi_1 = 6\pi_1 = 1 . \]</span>
Therefore <span class="math inline">\(\pi_1 = \frac16\)</span>. Substituting this into our previous expressions, we get <span class="math inline">\(\pi_2 = 2\pi_1 = \frac13\)</span> and <span class="math inline">\(\pi_3 = 3\pi_1 = \frac12\)</span>.
Thus the solution is
<span class="math display">\[ \boldsymbol\pi = \left( \tfrac16 \quad \tfrac13 \quad \tfrac12 \right) . \]</span></p>
<p>We can check our answer with the discarded third equation, just to make sure we didn’t make any mistakes. We get
<span class="math display">\[ \pi_3 = \tfrac14\pi_1 + \tfrac14\pi_2 + \tfrac34\pi_3 = \tfrac14\tfrac16 + \tfrac14\tfrac13+\tfrac34\tfrac12 = \tfrac1{24} + \tfrac2{24} + \tfrac{9}{24} = \tfrac{1}{2} , \]</span>
which is as it should be.</p>
</div>
</div>
<div id="exist-unique" class="section level2">
<h2><span class="header-section-number">10.3</span> Existence and uniqueness</h2>
<p>Given a Markov chain its natural to ask:</p>
<ol style="list-style-type: decimal">
<li>Does a stationary distribution exist?</li>
<li>If a stationary distribution does exists, is there only one, or are there be many stationary distributions?</li>
</ol>
<p>The answer is given by the following very important theorem.</p>
<div class="theorem">
<p><span id="thm:statex" class="theorem"><strong>Theorem 10.1  </strong></span>Consider an irreducible Markov chain.</p>
<ul>
<li>If the Markov chain is positive recurrent, then a stationary distribution <span class="math inline">\(\boldsymbol \pi\)</span> exists, is unique, and is given by <span class="math inline">\(\pi_i = 1/\mu_{i}\)</span>, where <span class="math inline">\(\mu_{i}\)</span> is the expected return time to state <span class="math inline">\(i\)</span>.</li>
<li>If the Markov chain is null recurrent or transient, then no stationary distribution exists.</li>
</ul>
</div>
<p>We give <a href="S10-stationary-distributions.html#stat-proof">an optional and nonexaminable proof to the first part below</a>.</p>
<p>In our no-claims discount example, the chain is irreducible and, like all finite state irreducible chains, it is positive recurrent. Thus the stationary distribution <span class="math inline">\(\boldsymbol\pi = (\tfrac{1}{13}, \tfrac{3}{13}, \tfrac{9}{13})\)</span> we found is the unique stationary distribution for that chain.
Once we have the stationary distribution <span class="math inline">\(\boldsymbol\pi\)</span>, we get the expected return times <span class="math inline">\(\mu_i = 1/\pi_i\)</span> for free: the expected return times are <span class="math inline">\(\mu_1 = 13\)</span>, <span class="math inline">\(\mu_2 = \frac{13}{3} = 4.33\)</span>, and <span class="math inline">\(\mu_3 = \frac{13}{9} = 1.44\)</span>.</p>
<p>Note the condition in Theorem <a href="S10-stationary-distributions.html#thm:statex">10.1</a> that the Markov chain is irreducible. What if the Markov chain is not irreducible, so has more than one communicating class? We can work out what must happen from the theorem:</p>
<ul>
<li>If none of the classes are positive recurrent, then no stationary distribution exists.</li>
<li>If exactly one of the classes is positive recurrent (and therefore closed), then there exists a unique stationary distribution, supported only on that closed class.</li>
<li>If more the one of the classes are positive recurrent, then many stationary distributions will exist.</li>
</ul>
<div class="example">
<p><span id="exm:stat-rw" class="example"><strong>Example 10.2  </strong></span>Consider the simple random walk with <span class="math inline">\(p \neq 0,1\)</span>. This Markov chain is irreducible, and is null recurrent for <span class="math inline">\(p = \frac12\)</span> and transient for <span class="math inline">\(p \neq \frac12\)</span>. Either way, the theorem tells us that no stationary distribution exists.</p>
</div>
<div class="example">
<p><span id="exm:stat-two" class="example"><strong>Example 10.3  </strong></span>Consider the Markov chain with transition matrix
<span class="math display">\[ \mathsf P = \begin{pmatrix} \frac12 &amp; \frac12 &amp; 0 &amp; 0 \\
\frac12 &amp; \frac12 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \frac14 &amp; \frac34\\
0 &amp; 0 &amp; \frac12 &amp; \frac12\end{pmatrix} . \]</span>
This chain has two closed positive recurrent classes, <span class="math inline">\(\{1,2\}\)</span> and <span class="math inline">\(\{3,4\}\)</span>.</p>
<p>Solving <span class="math inline">\(\boldsymbol\pi = \boldsymbol\pi\mathsf P\)</span> gives
<span class="math display">\[\begin{align*}
    \pi_1 = \tfrac12 \pi_1 + \tfrac12\pi_2 \qquad &amp;\Rightarrow \qquad \phantom{3}\pi_1 = \pi_2 \\
    \pi_2 = \tfrac12 \pi_1 + \tfrac12\pi_2 \qquad &amp;\Rightarrow \qquad \phantom{3}\pi_1 = \pi_2 \\
    \pi_3 = \tfrac14 \pi_3 + \tfrac12\pi_4 \qquad &amp;\Rightarrow \qquad 3\pi_3 = 2\pi_4 \\
    \pi_4 = \tfrac34 \pi_3 + \tfrac12\pi_4 \qquad &amp;\Rightarrow \qquad 3\pi_3 = 2\pi_4 , 
\end{align*}\]</span>
giving us the same two constraints twice each. We also have the normalising condition <span class="math inline">\(\pi_1 + \pi_2+\pi_3+\pi_4 = 1\)</span>. If we let <span class="math inline">\(\pi_1 + \pi_2 = \alpha\)</span> and <span class="math inline">\(\pi_3 + \pi_4 = 1-\alpha\)</span>, we see that
<span class="math display">\[ \boldsymbol\pi = \left(\tfrac12\alpha\quad \tfrac12\alpha\quad \tfrac25(1-\alpha)\quad \tfrac35(1-\alpha)\right) \]</span>
is a stationary distribution for any <span class="math inline">\(0 \leq \alpha \leq 1\)</span>, so we have infinitely many stationary distributions.</p>
</div>
</div>
<div id="stat-proof" class="section level2">
<h2><span class="header-section-number">10.4</span> Proof of existence and uniqueness</h2>
<div class="mysummary">
<p><em>This subsection is optional and nonexaminable.</em></p>
</div>
<p>It’s very important to be able to find the stationary distribution(s) of a Markov chain – you can reasonably expect a question on this to turn up on the exam. You should also know the conditions for existence and uniqueness of the stationary distribution. Being able to <em>prove</em> existence and uniqueness is less important, although for completeness we will do so here.</p>
<p>Theorem <a href="S10-stationary-distributions.html#thm:statex">10.1</a> had two points. The more important point was that irreducible, positive recurrent Markov chains have a stationary distribution, that it is unique, and that it is given by <span class="math inline">\(\pi_i = 1/\mu_i\)</span>. We give a proof of that below, doing the existence and uniqueness parts separately.
The less important point was that null recurrent and transitive Markov chains do not have a stationary distribution, and this is more fiddly. You can find a proof (usually in multiple parts) in books such as Norris, <a href="https://www.statslab.cam.ac.uk/~james/Markov/"><em>Markov Chains</em></a>, Section 1.7.</p>
<div class="thpart">
<p><strong>Existence:</strong> <em>Every positive recurrent Markov chain has a stationary distribution.</em></p>
</div>
<p>Before we start, one last definition. Let us call a vector <span class="math inline">\(\boldsymbol\nu\)</span> a <strong>stationary vector</strong> if <span class="math inline">\(\boldsymbol\nu \mathsf P = \boldsymbol\nu\)</span>. This is exactly like a stationary distribution, except without the normalisation condition that it has to sum to 1.</p>
<div class="proof">
<p><span id="unlabeled-div-13" class="proof"><em>Proof</em>. </span>Suppose that <span class="math inline">\((X_n)\)</span> is recurrent (either positive or null, for the moment).</p>
<p>Our first task will be to find a stationary vector. Fix an initial state <span class="math inline">\(k\)</span>, and let <span class="math inline">\(\nu_i\)</span> be the expected number of visits to <span class="math inline">\(i\)</span> before we return back to <span class="math inline">\(k\)</span>. That is,
<span class="math display">\[\begin{align*}
\nu_i &amp;= \mathbb E \# \{\text{visits to $i$ before returning to $k$}\} \\
      &amp;= \mathbb E \sum_{n=1}^{M_k} \mathbb P(X_n = i \mid X_0 = k) \\
      &amp;= \sum_{n=1}^\infty \mathbb P(X_n = i \text{ and } n \leq M_k \mid X_0 = k)  ,
\end{align*}\]</span>
where <span class="math inline">\(M_k\)</span> is <a href="#S08-return-times">the return time, as in Section 8</a>.
Let us note for later use that, under this definition, <span class="math inline">\(\nu_k = 1\)</span>, because the only visit to <span class="math inline">\(k\)</span> is the return to <span class="math inline">\(k\)</span> itself.</p>
<p>Since <span class="math inline">\(\boldsymbol\nu\)</span> is counting the number of visits to different states in a certain (random) time, it seems plausible that <span class="math inline">\(\boldsymbol\nu\)</span> suitably normalised could be a stationary distribution, meaning that <span class="math inline">\(\boldsymbol\nu\)</span> itself could be a stationary vector. Let’s check.</p>
<p>We want to show that <span class="math inline">\(\sum_i \nu_i p_{ij} = \nu_j\)</span>. Let’s see what we have:
<span class="math display">\[\begin{align*}
\sum_{i \in \mathcal S} \nu_i p_{ij} &amp;= \sum_{i \in \mathcal S} \sum_{n=1}^\infty \mathbb P(X_n = i \text{ and } n \leq M_k \mid X_0 = k) \, p_{ij} \\
&amp;= \sum_{n=1}^\infty \sum_{i \in \mathcal S} \mathbb P(X_n = i \text{ and } X_{n+1} = j \text{ and } n \leq M_k \mid X_0 = k) \\
&amp;= \sum_{n=1}^\infty \mathbb P(X_{n+1} = j \text{ and } n \leq M_k \mid X_0 = k) .
\end{align*}\]</span>
(Exchanging the order of the sums is legitimate, because recurrence of the chain means that <span class="math inline">\(M_k\)</span> is finite with probability 1.)
We can now do a cheeky bit of monkeying around with the index <span class="math inline">\(n\)</span>, by swapping out the visit to <span class="math inline">\(k\)</span> at time <span class="math inline">\(M_k\)</span> with the visit to <span class="math inline">\(k\)</span> at time <span class="math inline">\(0\)</span>. This means instead of counting the visits from <span class="math inline">\(1\)</span> to <span class="math inline">\(M_k\)</span>, we can count the visits from <span class="math inline">\(0\)</span> to <span class="math inline">\(M_k - 1\)</span>. Shuffling the index about, we get
<span class="math display">\[\begin{align*}
\sum_{i \in \mathcal S} \nu_i p_{ij} &amp;= \sum_{n=0}^\infty \mathbb P(X_{n+1} = j \text{ and } n \leq M_k-1 \mid X_0 = k) \\
&amp;= \sum_{n+1=1}^\infty \mathbb P(X_{n+1} = j \text{ and } n+1 \leq M_k \mid X_0 = k) \\
&amp;= \sum_{n=1}^\infty \mathbb P(X_{n} = j \text{ and } n \leq M_k \mid X_0 = k) \\
&amp;= \nu_j .
\end{align*}\]</span>
So <span class="math inline">\(\boldsymbol\nu\)</span> is indeed a stationary vector.</p>
<p>We now want normalise <span class="math inline">\(\boldsymbol\nu\)</span> into a stationary distribution by dividing through by <span class="math inline">\(\sum_i \nu_i\)</span>. We can do this if <span class="math inline">\(\sum_i \nu_i\)</span> is finite. But <span class="math inline">\(\sum_i \nu_i\)</span> is the expected total number of visits to all states before return to <span class="math inline">\(k\)</span>, which is precisely the expected return time <span class="math inline">\(\mu_k\)</span>. Now we use assume that <span class="math inline">\((X_n)\)</span> is <em>positive</em> recurrent. This means that <span class="math inline">\(\mu_k\)</span> is finite, so <span class="math inline">\(\boldsymbol\pi = (1/\mu_k) \boldsymbol\nu\)</span> is a stationary distribution.</p>
</div>
<div class="thpart">
<p><strong>Uniqueness:</strong> <em>For an irreducible, positive recurrent Markov chain, the stationary distribution is unique and is given by <span class="math inline">\(\pi_i = 1/\mu_i\)</span>.</em></p>
</div>
<p>I read the following proof in Stirzaker, <a href="https://leeds.primo.exlibrisgroup.com/permalink/44LEE_INST/13rlbcs/alma991013131349705181"><em>Elementary Probability</em></a>, Section 9.5.</p>
<div class="proof">
<p><span id="unlabeled-div-14" class="proof"><em>Proof</em>. </span>Suppose the Markov chain is irreducible and positive recurrent, and suppose <span class="math inline">\(\boldsymbol\pi\)</span> is a stationary distribution. We want to show that <span class="math inline">\(\pi_i = 1/\mu_i\)</span> for all <span class="math inline">\(i\)</span>.</p>
<p>The only equation we have for <span class="math inline">\(\mu_k\)</span> is <a href="#S08-return-times">this one from Section 8</a>:
<span class="math display" id="eq:pf2">\[\begin{equation}
\mu_k = 1 + \sum_j p_{kj} \eta_{jk} . \tag{10.2}
\end{equation}\]</span>
Since that involves the expected hitting times <span class="math inline">\(\eta_{ik}\)</span>, let’s write down <a href="#S08-return-times">the equation for them</a> too:
<span class="math display" id="eq:pf1">\[\begin{equation}
\eta_{ik} = 1 + \sum_j p_{ij} \eta_{jk} \qquad \text{for all $i \neq k$.} \tag{10.3}
\end{equation}\]</span></p>
<p>In order to apply the fact that <span class="math inline">\(\boldsymbol\pi\)</span> is a stationary distribution, we’d like to get these into an equation with <span class="math inline">\(\sum_i \pi_i p_{ij}\)</span> in it. Here’s a way we can do that:
Take <a href="S10-stationary-distributions.html#eq:pf1">(10.3)</a>, multiply it by <span class="math inline">\(\pi_i\)</span> and sum over all <span class="math inline">\(i \neq k\)</span>, to get
<span class="math display" id="eq:pf3">\[\begin{equation}
\sum_{i} \pi_i \eta_{ik} = \sum_{i \neq k} \pi_i + \sum_j \sum_{i \neq k} \pi_i p_{ij} \eta_{jk} . \tag{10.4}
\end{equation}\]</span>
(The sum on the left can be over all <span class="math inline">\(i\)</span>, since <span class="math inline">\(\eta_{kk} = 0\)</span>.)
Also, take <a href="S10-stationary-distributions.html#eq:pf2">(10.2)</a> and multiply it by <span class="math inline">\(\pi_k\)</span> to get
<span class="math display" id="eq:pf4">\[\begin{equation}
\pi_k \mu_k = \pi_k + \sum_j \pi_k p_{kj} \eta_{jk} \tag{10.5}
\end{equation}\]</span>
Now add <a href="S10-stationary-distributions.html#eq:pf3">(10.4)</a> and <a href="S10-stationary-distributions.html#eq:pf4">(10.5)</a> together to get
<span class="math display">\[
\sum_{i} \pi_i \eta_{ik} + \pi_k \mu_k = \sum_i \pi_i + \sum_j \sum_i\pi_i p_{ij} \eta_{jk} .
\]</span></p>
<p>We can now use <span class="math inline">\(\sum_i\pi_i p_{ij} = \pi_j\)</span>, along with <span class="math inline">\(\sum_i \pi_i = 1\)</span>, to get
<span class="math display">\[ \sum_{i} \pi_i \eta_{ik} + \pi_k \mu_k = 1 + \sum_j \pi_j \eta_{jk} . \]</span></p>
<p>But the first term on the left and the last term on the right are equal, and because the Markov chain is irreducible and positive recurrent, they are finite. (That was <a href="S09-recurrence-transience.html#S09-lemma">our lemma in the previous section</a>.) Thus we’re allowed to subtract them, and we get <span class="math inline">\(\pi_k \mu_k = 1\)</span>, which is indeed <span class="math inline">\(\pi_k = 1/\mu_k\)</span>. We can repeat the argument for every choice of <span class="math inline">\(k\)</span>.</p>
</div>
<div class="mysummary">
<p><strong>In the next section</strong>, we see how the stationary distribution tells us very important things about the long-term behaviour of a Markov chain.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="S09-recurrence-transience.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="P05.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math2750.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

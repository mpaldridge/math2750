<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 6 Examples from actuarial science | MATH2750 Introduction to Markov Processes</title>
  <meta name="description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 6 Examples from actuarial science | MATH2750 Introduction to Markov Processes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://mpaldridge.github.io/math2750/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 6 Examples from actuarial science | MATH2750 Introduction to Markov Processes" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="S05-markov-chains.html"/>
<link rel="next" href="P03.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH2750 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-module"><i class="fa fa-check"></i>Organisation of MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-computing"><i class="fa fa-check"></i>Computing worksheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#dropin"><i class="fa fa-check"></i>Drop-in sessions</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#team"><i class="fa fa-check"></i>Microsoft Team</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#time"><i class="fa fa-check"></i>Time management</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#exam"><i class="fa fa-check"></i>Exam</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#ask"><i class="fa fa-check"></i>Who should I ask about…?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-content"><i class="fa fa-check"></i>Content of MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#prereqs"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#books"><i class="fa fa-check"></i>Books</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#finally"><i class="fa fa-check"></i>And finally…</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Discrete time Markov chains</b></span></li>
<li class="chapter" data-level="1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html"><i class="fa fa-check"></i><b>1</b> Stochastic processes and the Markov property</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#models"><i class="fa fa-check"></i><b>1.1</b> Deterministic and random models</a></li>
<li class="chapter" data-level="1.2" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#stochastic-processes"><i class="fa fa-check"></i><b>1.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="1.3" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#markov-property"><i class="fa fa-check"></i><b>1.3</b> Markov property</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-random-walk.html"><a href="S02-random-walk.html"><i class="fa fa-check"></i><b>2</b> Random walk</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-random-walk.html"><a href="S02-random-walk.html#simple-random-walk"><i class="fa fa-check"></i><b>2.1</b> Simple random walk</a></li>
<li class="chapter" data-level="2.2" data-path="S02-random-walk.html"><a href="S02-random-walk.html#general-random-walks"><i class="fa fa-check"></i><b>2.2</b> General random walks</a></li>
<li class="chapter" data-level="2.3" data-path="S02-random-walk.html"><a href="S02-random-walk.html#exact-distribution"><i class="fa fa-check"></i><b>2.3</b> Exact distribution of the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html"><i class="fa fa-check"></i><b>3</b> Gambler’s ruin</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-chain"><i class="fa fa-check"></i><b>3.1</b> Gambler’s ruin Markov chain</a></li>
<li class="chapter" data-level="3.2" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-probability"><i class="fa fa-check"></i><b>3.2</b> Probability of ruin</a></li>
<li class="chapter" data-level="3.3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#expected-duration"><i class="fa fa-check"></i><b>3.3</b> Expected duration of the game</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-ldes.html"><a href="S04-ldes.html"><i class="fa fa-check"></i><b>4</b> Linear difference equations</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-ldes.html"><a href="S04-ldes.html#hom-ldes"><i class="fa fa-check"></i><b>4.1</b> Homogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.2" data-path="S04-ldes.html"><a href="S04-ldes.html#ruin-probability-solve"><i class="fa fa-check"></i><b>4.2</b> Probability of ruin for the gambler’s ruin</a></li>
<li class="chapter" data-level="4.3" data-path="S04-ldes.html"><a href="S04-ldes.html#inhom-ldes"><i class="fa fa-check"></i><b>4.3</b> Inhomogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.4" data-path="S04-ldes.html"><a href="S04-ldes.html#duration-solve"><i class="fa fa-check"></i><b>4.4</b> Expected duration for the gambler’s ruin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem sheet 2</a></li>
<li class="chapter" data-level="" data-path="A1.html"><a href="A1.html"><i class="fa fa-check"></i>Assessment 1</a></li>
<li class="chapter" data-level="5" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html"><i class="fa fa-check"></i><b>5</b> Discrete time Markov chains</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#thmc"><i class="fa fa-check"></i><b>5.1</b> Time homogeneous discrete time Markov chains</a></li>
<li class="chapter" data-level="5.2" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#S05-example"><i class="fa fa-check"></i><b>5.2</b> A two-state example</a></li>
<li class="chapter" data-level="5.3" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#n-step"><i class="fa fa-check"></i><b>5.3</b> <em>n</em>-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-examples.html"><a href="S06-examples.html"><i class="fa fa-check"></i><b>6</b> Examples from actuarial science</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-examples.html"><a href="S06-examples.html#S06-example1"><i class="fa fa-check"></i><b>6.1</b> A simple no-claims discount model</a></li>
<li class="chapter" data-level="6.2" data-path="S06-examples.html"><a href="S06-examples.html#S06-example2"><i class="fa fa-check"></i><b>6.2</b> An accident model with memory</a></li>
<li class="chapter" data-level="6.3" data-path="S06-examples.html"><a href="S06-examples.html#S06-example3"><i class="fa fa-check"></i><b>6.3</b> A no-claims discount model with memory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem sheet 3</a></li>
<li class="chapter" data-level="7" data-path="S07-classes.html"><a href="S07-classes.html"><i class="fa fa-check"></i><b>7</b> Class structure</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-classes.html"><a href="S07-classes.html#comm-classes"><i class="fa fa-check"></i><b>7.1</b> Communicating classes</a></li>
<li class="chapter" data-level="7.2" data-path="S07-classes.html"><a href="S07-classes.html#periodicity"><i class="fa fa-check"></i><b>7.2</b> Periodicity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html"><i class="fa fa-check"></i><b>8</b> Hitting times</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#hitting-definitions"><i class="fa fa-check"></i><b>8.1</b> Hitting probabilities and expected hitting times</a></li>
<li class="chapter" data-level="8.2" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-times"><i class="fa fa-check"></i><b>8.2</b> Return times</a></li>
<li class="chapter" data-level="8.3" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-rw"><i class="fa fa-check"></i><b>8.3</b> Hitting and return times for the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem sheet 4</a></li>
<li class="chapter" data-level="9" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html"><i class="fa fa-check"></i><b>9</b> Recurrence and transience</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-trans-def"><i class="fa fa-check"></i><b>9.1</b> Recurrent and transient states</a></li>
<li class="chapter" data-level="9.2" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-tran-classes"><i class="fa fa-check"></i><b>9.2</b> Recurrent and transient classes</a></li>
<li class="chapter" data-level="9.3" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-positive-null"><i class="fa fa-check"></i><b>9.3</b> Positive and null recurrence</a></li>
<li class="chapter" data-level="9.4" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-strong-markov"><i class="fa fa-check"></i><b>9.4</b> Strong Markov property</a></li>
<li class="chapter" data-level="9.5" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-lemma"><i class="fa fa-check"></i><b>9.5</b> A useful lemma</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html"><i class="fa fa-check"></i><b>10</b> Stationary distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#def-stationary-definition"><i class="fa fa-check"></i><b>10.1</b> Definition of stationary distribution</a></li>
<li class="chapter" data-level="10.2" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#find-stationary"><i class="fa fa-check"></i><b>10.2</b> Finding a stationary distribution</a></li>
<li class="chapter" data-level="10.3" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#exist-unique"><i class="fa fa-check"></i><b>10.3</b> Existence and uniqueness</a></li>
<li class="chapter" data-level="10.4" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#stat-proof"><i class="fa fa-check"></i><b>10.4</b> Proof of existence and uniqueness</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem sheet 5</a></li>
<li class="chapter" data-level="11" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html"><i class="fa fa-check"></i><b>11</b> Long-term behaviour of Markov chains</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#equilibrium"><i class="fa fa-check"></i><b>11.1</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="11.2" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#convergence-examples"><i class="fa fa-check"></i><b>11.2</b> Examples of convergence and non-convergence</a></li>
<li class="chapter" data-level="11.3" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-ergodic"><i class="fa fa-check"></i><b>11.3</b> Ergodic theorem</a></li>
<li class="chapter" data-level="11.4" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-proofs"><i class="fa fa-check"></i><b>11.4</b> Proofs of the limit and ergodic theorems</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S12-revision-i.html"><a href="S12-revision-i.html"><i class="fa fa-check"></i><b>12</b> End of of Part I: Discrete time Markov chains</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-revision-i.html"><a href="S12-revision-i.html#todo-revision"><i class="fa fa-check"></i><b>12.1</b> Things to do</a></li>
<li class="chapter" data-level="12.2" data-path="S12-revision-i.html"><a href="S12-revision-i.html#summary-i"><i class="fa fa-check"></i><b>12.2</b> Summary of Part I</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P06.html"><a href="P06.html"><i class="fa fa-check"></i>Problem sheet 6</a></li>
<li class="chapter" data-level="" data-path="A3.html"><a href="A3.html"><i class="fa fa-check"></i>Assessment 3</a></li>
<li class="part"><span><b>Part II: Continuous time Markov jump processes</b></span></li>
<li class="chapter" data-level="13" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html"><i class="fa fa-check"></i><b>13</b> Poisson process with Poisson increments</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-dist"><i class="fa fa-check"></i><b>13.1</b> Poisson distribution</a></li>
<li class="chapter" data-level="13.2" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-def-poisson"><i class="fa fa-check"></i><b>13.2</b> Definition 1: Poisson increments</a></li>
<li class="chapter" data-level="13.3" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#summed-marked"><i class="fa fa-check"></i><b>13.3</b> Summed and marked Poisson processes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html"><i class="fa fa-check"></i><b>14</b> Poisson process with exponential holding times</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#exponential"><i class="fa fa-check"></i><b>14.1</b> Exponential distribution</a></li>
<li class="chapter" data-level="14.2" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#definition-2-exponential-holding-times"><i class="fa fa-check"></i><b>14.2</b> Definition 2: exponential holding times</a></li>
<li class="chapter" data-level="14.3" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#cont-markov"><i class="fa fa-check"></i><b>14.3</b> Markov property in continuous time</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P07.html"><a href="P07.html"><i class="fa fa-check"></i>Problem sheet 7</a></li>
<li class="chapter" data-level="15" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html"><i class="fa fa-check"></i><b>15</b> Poisson process in infinitesimal time periods</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#infinitesimal"><i class="fa fa-check"></i><b>15.1</b> Definition 3: increments in infinitesimal time</a></li>
<li class="chapter" data-level="15.2" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#sum2"><i class="fa fa-check"></i><b>15.2</b> Example: sum of two Poisson processes</a></li>
<li class="chapter" data-level="15.3" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#forward"><i class="fa fa-check"></i><b>15.3</b> Forward equations and proof of equivalence</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html"><i class="fa fa-check"></i><b>16</b> Counting processes</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html#birth-processes"><i class="fa fa-check"></i><b>16.1</b> Birth processes</a></li>
<li class="chapter" data-level="16.2" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html#TIPP"><i class="fa fa-check"></i><b>16.2</b> Time inhomogeneous Poisson process</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P08.html"><a href="P08.html"><i class="fa fa-check"></i>Problem Sheet 8</a></li>
<li class="chapter" data-level="17" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html"><i class="fa fa-check"></i><b>17</b> Continuous time Markov jump processes</a>
<ul>
<li class="chapter" data-level="17.1" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#jump-holding"><i class="fa fa-check"></i><b>17.1</b> Jump chain and holding times</a></li>
<li class="chapter" data-level="17.2" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#CTMC-examples"><i class="fa fa-check"></i><b>17.2</b> Examples</a></li>
<li class="chapter" data-level="17.3" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#explosion"><i class="fa fa-check"></i><b>17.3</b> A brief note on explosion</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html"><i class="fa fa-check"></i><b>18</b> Forward and backward equations</a>
<ul>
<li class="chapter" data-level="18.1" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#jump-infinitesimal"><i class="fa fa-check"></i><b>18.1</b> Transitions in infinitesimal time periods</a></li>
<li class="chapter" data-level="18.2" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#semigroup"><i class="fa fa-check"></i><b>18.2</b> Transition semigroup and the forward and backward equations</a></li>
<li class="chapter" data-level="18.3" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#matrix-exp"><i class="fa fa-check"></i><b>18.3</b> Matrix exponential</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P09.html"><a href="P09.html"><i class="fa fa-check"></i>Problem Sheet 9</a></li>
<li class="chapter" data-level="19" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html"><i class="fa fa-check"></i><b>19</b> Class structure and hitting times</a>
<ul>
<li class="chapter" data-level="19.1" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#classes-cont"><i class="fa fa-check"></i><b>19.1</b> Communicating classes</a></li>
<li class="chapter" data-level="19.2" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#periods2"><i class="fa fa-check"></i><b>19.2</b> A brief note on periodicity</a></li>
<li class="chapter" data-level="19.3" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#hitting2"><i class="fa fa-check"></i><b>19.3</b> Hitting probabilities and expected hitting times</a></li>
<li class="chapter" data-level="19.4" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#recurrence-transience2"><i class="fa fa-check"></i><b>19.4</b> Recurrence and transience</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html"><i class="fa fa-check"></i><b>20</b> Long-term behaviour of Markov jump processes</a>
<ul>
<li class="chapter" data-level="20.1" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#stationary-jump"><i class="fa fa-check"></i><b>20.1</b> Stationary distributions</a></li>
<li class="chapter" data-level="20.2" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#convergernce-cont"><i class="fa fa-check"></i><b>20.2</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="20.3" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#ergodic-cont"><i class="fa fa-check"></i><b>20.3</b> Ergodic theorem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P10.html"><a href="P10.html"><i class="fa fa-check"></i>Problem Sheet 10</a></li>
<li class="chapter" data-level="" data-path="A4.html"><a href="A4.html"><i class="fa fa-check"></i>Assessment 4</a></li>
<li class="chapter" data-level="21" data-path="S21-queues.html"><a href="S21-queues.html"><i class="fa fa-check"></i><b>21</b> Queues</a>
<ul>
<li class="chapter" data-level="21.1" data-path="S21-queues.html"><a href="S21-queues.html#MMinf"><i class="fa fa-check"></i><b>21.1</b> M/M/∞ infinite server process</a></li>
<li class="chapter" data-level="21.2" data-path="S21-queues.html"><a href="S21-queues.html#MM1"><i class="fa fa-check"></i><b>21.2</b> M/M/1 single server queue</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="S22-end.html"><a href="S22-end.html"><i class="fa fa-check"></i><b>22</b> End of Part II: Continuous time Markov jump processes</a>
<ul>
<li class="chapter" data-level="22.1" data-path="S22-end.html"><a href="S22-end.html#summary-ii"><i class="fa fa-check"></i><b>22.1</b> Summary of Part II</a></li>
<li class="chapter" data-level="22.2" data-path="S22-end.html"><a href="S22-end.html#exam-faqs"><i class="fa fa-check"></i><b>22.2</b> Exam FAQs</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P11.html"><a href="P11.html"><i class="fa fa-check"></i>Problem Sheet 11</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html"><i class="fa fa-check"></i>Computational worksheets</a>
<ul>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#C-about"><i class="fa fa-check"></i>About the computational worksheets</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#R-access"><i class="fa fa-check"></i>How to access R</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#R-background"><i class="fa fa-check"></i>R background</a></li>
</ul></li>
<li class="divider"></li>
<li></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2750 Introduction to Markov Processes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S06-examples" class="section level1" number="6">
<h1><span class="header-section-number">Section 6</span> Examples from actuarial science</h1>
<div class="mysummary">
<ul>
<li>Three Markov chain models for insurance problems</li>
</ul>
</div>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/t3M52DfVb_U">
</iframe>
</div>
</div>
<p>In this lecture we’ll set up three simple models for an insurance company that can be analysed using ideas about Markov chains. The first example has a direct Markov chain model. For the second and third examples, we will have to be clever to find a Markov chain associated to the situation.</p>
<div id="S06-example1" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> A simple no-claims discount model</h2>
<p>A motor insurance company puts policy holders into three categories:</p>
<ul>
<li>no discount on premiums (state 1)</li>
<li>25% discount on premiums (state 2)</li>
<li>50% discount on premiums (state 3)</li>
</ul>
<p>New policy holders start with no discount (state 1). Following a year with no insurance claims, policy holders move up one level of discount. If they start the year in state 3 and make no claim, they remain in state 3. Following a year with at least one claim, they move down one level of discount. If they start the year in state 1 and make at least one claim, they remain in state 1. The insurance company believes that probability that a motorist has a claim free year is <span class="math inline">\(\frac34\)</span>.</p>
<p>We can model this directly as a Markov chain:</p>
<ul>
<li>the state space <span class="math inline">\(\mathcal S = \{1,2,3\}\)</span> is discrete;</li>
<li>the time index is discrete, as we have one discount level each year;</li>
<li>the probability of being in a certain state at a future time is completely determined by the present state (the Markov property);</li>
<li>the one-step transition probabilities are not time dependent (time homogeneous).</li>
</ul>
<p>The transition probability and transition diagram of the Markov chain are:
<span class="math display">\[ \mathsf P = \begin{pmatrix} \frac14 &amp; \frac34 &amp; 0 \\ \frac14 &amp; 0 &amp; \frac34 \\ 0 &amp; \frac14 &amp; \frac34 \end{pmatrix} . \]</span></p>
<div class="figure" style="text-align: center"><span id="fig:example1"></span>
<img src="math2750_files/figure-html/example1-1.png" alt="Transition diagram for the simple no-claims discount model" width="384" />
<p class="caption">
Figure 6.1: Transition diagram for the simple no-claims discount model
</p>
</div>
<div class="example">
<p><span id="exm:act1" class="example"><strong>Example 6.1  </strong></span><em>What is the probability of having a 50% reduction to your premium three years from now, given that you currently have no reduction on the premium?</em></p>
<p>We want to find the three-step transition probability
<span class="math display">\[
p_{13}(3) = \mathbb P(X_{3} = 3 \mid X_0=1) .
\]</span>
We can find this by summing over all paths <span class="math inline">\(1 \to k_1 \to k_2 \to 3\)</span>. There are two such paths, <span class="math inline">\(1 \to 1 \to 2 \to 3\)</span> and <span class="math inline">\(1 \to 2 \to 3 \to 3\)</span>. Thus
<span class="math display">\[ p_{13}(3) = p_{11}p_{12}p_{23} + p_{12}p_{23}p_{33} = \frac14 \cdot\frac34 \cdot\frac34 + \frac34 \cdot\frac34 \cdot\frac34 = \frac{36}{64} = \frac{9}{16} . \]</span></p>
<p>Alternatively, we could directly calculate all the three-step transition probabilities by the matrix method, to get
<span class="math display">\[ \mathsf P(3) = \mathsf P^3 = \mathsf{PPP} = \frac{1}{64} \begin{pmatrix} 7 &amp; 21 &amp; 36 \\ 7 &amp; 12 &amp; 45 \\ 4 &amp; 15 &amp; 45 \end{pmatrix} .\]</span>
(You can check this yourself, if you want.) The desired <span class="math inline">\(p_{13}(3)\)</span> is the top right entry <span class="math inline">\(36/64 = 9/16\)</span>.</p>
</div>
</div>
<div id="S06-example2" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> An accident model with memory</h2>
<p>Sometimes, we are presented with a situation where the “obvious” stochastic process is not a Markov chain. But sometimes we can find a related process that <em>is</em> a Markov chain, and study that instead. As an example of this, we consider at a different accident model.</p>
<p>According to a different model, a motorist’s <span class="math inline">\(n\)</span>th year of driving is either accident free, or has exactly one accident. (The model does not allow for more than one accident in a year.) Let <span class="math inline">\(Y_n\)</span> be a random variable so that,
<span class="math display">\[
Y_n=\begin{cases}
0&amp;\text{ if the motorist has no accident in year $n$,}\\
1&amp;\text{ if the motorist has one accident in year $n$.}
\end{cases}
\]</span>
This defines a stochastic process <span class="math inline">\((Y_n)\)</span> with finite state space <span class="math inline">\(\mathcal{S}=\{0,1\}\)</span> and discrete time <span class="math inline">\(n = 1,2,3,\dots\)</span>.</p>
<p>The probability of an accident in year <span class="math inline">\(n+1\)</span> is modelled as a function of the total number of previous accidents over a function of the number of years in the policy; that is,
<span class="math display">\[
\mathbb P(Y_{n+1}= 1 \mid Y_n=y_{n},\dots ,Y_2=y_{2},Y_1=y_{1} )=\frac{f(y_1+y_2+\cdots +y_n)}{g(n)},
\]</span>
and <span class="math inline">\(Y_{n+1} = 0\)</span> otherwise,
where <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are non-negative increasing functions with <span class="math inline">\(0\leq f(m)\leq g(m)\)</span> for all <span class="math inline">\(m\)</span>. (We’ll come back to these conditions in a moment.)</p>
<p>Unfortunately <span class="math inline">\((Y_n)\)</span> is <em>not</em> a Markov chain – it’s clear that <span class="math inline">\(Y_{n+1}\)</span> depends not only on <span class="math inline">\(Y_n\)</span>, the number accidents this year, but the entire history <span class="math inline">\(Y_1, Y_2, \dots, Y_n\)</span>.</p>
<p>However, we have a cunning work-around. Define <span class="math inline">\(X_n=\sum_{i=1}^n Y_i\)</span> to be the total number of accidents up to year <span class="math inline">\(n\)</span>. Then <span class="math inline">\((X_n)\)</span> <em>is</em> a Markov chain. In fact, we have
<span class="math display">\[\begin{align*}
    \mathbb P(X_{n+1}={}&amp;{}x_{n}+1\mid X_n=x_n, \dots, X_2=x_2, X_1=x_1)\\
    &amp;=\mathbb P(Y_{n+1}=1\mid Y_n=x_n - x_{n-1}, \dots Y_2=x_2-x_1, Y_1=x_1)\\
    &amp;=\frac{f\big((x_n-x_{n-1}) +\cdots +(x_2-x_1) + x_1\big)}{g(n)}\\
    &amp;=\frac{f(x_n)}{g(n)},
\end{align*}\]</span>
and <span class="math inline">\(X_{n+1} = x_n\)</span> otherwise. This clearly depends only on <span class="math inline">\(x_n\)</span>. Thus we can use Markov chain techniques on <span class="math inline">\((X_n)\)</span> to lean about the non-Markov process <span class="math inline">\((Y_n)\)</span>.</p>
<p>Note that the probability that <span class="math inline">\(X_{n+1} = x_n\)</span> or <span class="math inline">\(x_n+ 1\)</span> depends not only on <span class="math inline">\(x_n\)</span> but also on the time <span class="math inline">\(n\)</span>. So this is a rare example of a time <em>inhomogeneous</em> Markov process, where the transition probabilities do depend on the time <span class="math inline">\(n\)</span>.</p>
<p>Before we move on, let’s think about the conditions we placed on this model. First, the condition that <span class="math inline">\(f\)</span> is increasing means that between drivers who have been driving the same number of years, we think the more accident-prone in the past is more likely to have an accident in the future. Second, the condition that <span class="math inline">\(g\)</span> is increasing means that between drivers who have had the same number of accidents, we think the one who has spread those accidents over a longer period of time is less likely to have accidents in the future. Third, the transition probabilities should lie in the range <span class="math inline">\([0,1]\)</span>; but since <span class="math inline">\(\sum_{i=1}^m y_i\leq m\)</span>, our condition <span class="math inline">\(0\leq f(m)\leq g(m)\)</span> guaranteed that this is the case.</p>
</div>
<div id="S06-example3" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> A no-claims discount model with memory</h2>
<p>Sometimes, we are presented with a stochastic process which is not a Markov chain, but where by altering the state space <span class="math inline">\(\mathcal{S}\)</span> we <em>can</em> end up with a process which <em>is</em> a Markov chain. As such, when making a model, it is important to think carefully about choice of state space. To see this we will return to the no-claims discount example.</p>
<p>Suppose now we have an model with four levels of discount:</p>
<ul>
<li>no discount (state 1)</li>
<li>20% discount (state 2)</li>
<li>40% discount (state 3)</li>
<li>60% discount (state 4)</li>
</ul>
<p>If a year is accident free, then the discount increases one level, to a maximum of 60%. This time, if the year has an accident, then the discount decreases by one level if the year previous to that was accident free, but decreases by <em>two</em> levels if the previous year had an accident as well, both to a minimum of no discount.</p>
<p>As before, the insurance company believes that probability that a motorist has a claim-free year is <span class="math inline">\(\frac34 = 0.75\)</span>.</p>
<p>We might consider the most natural choice of a state space, where the states are discount levels; say, <span class="math inline">\(\mathcal{S}=\{1,2,3,4\}\)</span>. But this is not a Markov chain, since if a policy holder has an accident, we may need to know about the past in order to determine probabilities for future states, which violates the Markov property. In particular, if a motorist is in state 3 (40% discount) and has an accident, they will either move down to level 2 (if they had not crashed the previous year, so had previously been in state 2) or to level 1 (if they had crashed the previous year, so had previously been in state 4) – but that depends on their previous level too, which the Markov property doesn’t allow. (You can check this is the only violation of the Markov property.)</p>
<p>However, we can be clever again, this time in the choice of our state space. Instead, we can split the 40% level into two different states: state “3a” if there was no accident the previous year, and state “3b” if there was an accident the previous year. Our states are now:</p>
<ul>
<li>no discount (state 1)</li>
<li>20% discount (state 2)</li>
<li>40% discount, no claim in previous year (state 3a)</li>
<li>40% discount, claim in previous year (state 3b)</li>
<li>60% discount (state 4)</li>
</ul>
<p>Now this <em>is</em> a Markov chain, because the new states 3s carry with them the memory of the previous year, to ensure the Markov property is preserved. Under the assumption of 25% of drivers having an accident each year, the transition matrix is
<span class="math display">\[
\mathsf P=\begin{pmatrix}
0.25 &amp; 0.75 &amp; 0 &amp; 0 &amp; 0\\
0.25 &amp; 0 &amp; 0.75 &amp; 0 &amp; 0\\
0 &amp; 0.25 &amp; 0 &amp; 0 &amp; 0.75\\
0.25 &amp; 0 &amp; 0 &amp; 0 &amp; 0.75\\
0 &amp; 0 &amp; 0 &amp; 0.25 &amp; 0.75\end{pmatrix}.
\]</span>
The transition diagram is shown below. (Recall that we don’t draw arrows with probability 0.)</p>
<div class="figure" style="text-align: center"><span id="fig:example3"></span>
<img src="math2750_files/figure-html/example3-1.png" alt="Transition diagram for the no-claims discount model with memory" width="480" />
<p class="caption">
Figure 6.2: Transition diagram for the no-claims discount model with memory
</p>
</div>
<p>Note that when we move up from state 2, we go to 3a (no accident in the previous year); but when we move down from state 4, we go to 3b (accident in the previous year).</p>
<div class="mysummary">
<p><strong>In the next section</strong>, we look at how to study big Markov chains by splitting them into smaller pieces called “classes”.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="S05-markov-chains.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="P03.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math2750.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

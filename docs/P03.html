<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Problem sheet 3 | MATH2750 Introduction to Markov Processes</title>
  <meta name="description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Problem sheet 3 | MATH2750 Introduction to Markov Processes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://mpaldridge.github.io/math2750/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Problem sheet 3 | MATH2750 Introduction to Markov Processes" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="S06-examples.html"/>
<link rel="next" href="S07-classes.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH2750 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-module"><i class="fa fa-check"></i>Organisation of MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-computing"><i class="fa fa-check"></i>Computing worksheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#dropin"><i class="fa fa-check"></i>Drop-in sessions</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#team"><i class="fa fa-check"></i>Microsoft Team</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#time"><i class="fa fa-check"></i>Time management</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#exam"><i class="fa fa-check"></i>Exam</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#ask"><i class="fa fa-check"></i>Who should I ask about…?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-content"><i class="fa fa-check"></i>Content of MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#prereqs"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#books"><i class="fa fa-check"></i>Books</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#finally"><i class="fa fa-check"></i>And finally…</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Discrete time Markov chains</b></span></li>
<li class="chapter" data-level="1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html"><i class="fa fa-check"></i><b>1</b> Stochastic processes and the Markov property</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#models"><i class="fa fa-check"></i><b>1.1</b> Deterministic and random models</a></li>
<li class="chapter" data-level="1.2" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#stochastic-processes"><i class="fa fa-check"></i><b>1.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="1.3" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#markov-property"><i class="fa fa-check"></i><b>1.3</b> Markov property</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-random-walk.html"><a href="S02-random-walk.html"><i class="fa fa-check"></i><b>2</b> Random walk</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-random-walk.html"><a href="S02-random-walk.html#simple-random-walk"><i class="fa fa-check"></i><b>2.1</b> Simple random walk</a></li>
<li class="chapter" data-level="2.2" data-path="S02-random-walk.html"><a href="S02-random-walk.html#general-random-walks"><i class="fa fa-check"></i><b>2.2</b> General random walks</a></li>
<li class="chapter" data-level="2.3" data-path="S02-random-walk.html"><a href="S02-random-walk.html#exact-distribution"><i class="fa fa-check"></i><b>2.3</b> Exact distribution of the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html"><i class="fa fa-check"></i><b>3</b> Gambler’s ruin</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-chain"><i class="fa fa-check"></i><b>3.1</b> Gambler’s ruin Markov chain</a></li>
<li class="chapter" data-level="3.2" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-probability"><i class="fa fa-check"></i><b>3.2</b> Probability of ruin</a></li>
<li class="chapter" data-level="3.3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#expected-duration"><i class="fa fa-check"></i><b>3.3</b> Expected duration of the game</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-ldes.html"><a href="S04-ldes.html"><i class="fa fa-check"></i><b>4</b> Linear difference equations</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-ldes.html"><a href="S04-ldes.html#hom-ldes"><i class="fa fa-check"></i><b>4.1</b> Homogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.2" data-path="S04-ldes.html"><a href="S04-ldes.html#ruin-probability-solve"><i class="fa fa-check"></i><b>4.2</b> Probability of ruin for the gambler’s ruin</a></li>
<li class="chapter" data-level="4.3" data-path="S04-ldes.html"><a href="S04-ldes.html#inhom-ldes"><i class="fa fa-check"></i><b>4.3</b> Inhomogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.4" data-path="S04-ldes.html"><a href="S04-ldes.html#duration-solve"><i class="fa fa-check"></i><b>4.4</b> Expected duration for the gambler’s ruin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem sheet 2</a></li>
<li class="chapter" data-level="" data-path="A1.html"><a href="A1.html"><i class="fa fa-check"></i>Assessment 1</a></li>
<li class="chapter" data-level="5" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html"><i class="fa fa-check"></i><b>5</b> Discrete time Markov chains</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#thmc"><i class="fa fa-check"></i><b>5.1</b> Time homogeneous discrete time Markov chains</a></li>
<li class="chapter" data-level="5.2" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#S05-example"><i class="fa fa-check"></i><b>5.2</b> A two-state example</a></li>
<li class="chapter" data-level="5.3" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#n-step"><i class="fa fa-check"></i><b>5.3</b> <em>n</em>-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-examples.html"><a href="S06-examples.html"><i class="fa fa-check"></i><b>6</b> Examples from actuarial science</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-examples.html"><a href="S06-examples.html#S06-example1"><i class="fa fa-check"></i><b>6.1</b> A simple no-claims discount model</a></li>
<li class="chapter" data-level="6.2" data-path="S06-examples.html"><a href="S06-examples.html#S06-example2"><i class="fa fa-check"></i><b>6.2</b> An accident model with memory</a></li>
<li class="chapter" data-level="6.3" data-path="S06-examples.html"><a href="S06-examples.html#S06-example3"><i class="fa fa-check"></i><b>6.3</b> A no-claims discount model with memory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem sheet 3</a></li>
<li class="chapter" data-level="7" data-path="S07-classes.html"><a href="S07-classes.html"><i class="fa fa-check"></i><b>7</b> Class structure</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-classes.html"><a href="S07-classes.html#comm-classes"><i class="fa fa-check"></i><b>7.1</b> Communicating classes</a></li>
<li class="chapter" data-level="7.2" data-path="S07-classes.html"><a href="S07-classes.html#periodicity"><i class="fa fa-check"></i><b>7.2</b> Periodicity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html"><i class="fa fa-check"></i><b>8</b> Hitting times</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#hitting-definitions"><i class="fa fa-check"></i><b>8.1</b> Hitting probabilities and expected hitting times</a></li>
<li class="chapter" data-level="8.2" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-times"><i class="fa fa-check"></i><b>8.2</b> Return times</a></li>
<li class="chapter" data-level="8.3" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-rw"><i class="fa fa-check"></i><b>8.3</b> Hitting and return times for the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem sheet 4</a></li>
<li class="chapter" data-level="9" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html"><i class="fa fa-check"></i><b>9</b> Recurrence and transience</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-trans-def"><i class="fa fa-check"></i><b>9.1</b> Recurrent and transient states</a></li>
<li class="chapter" data-level="9.2" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-tran-classes"><i class="fa fa-check"></i><b>9.2</b> Recurrent and transient classes</a></li>
<li class="chapter" data-level="9.3" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-positive-null"><i class="fa fa-check"></i><b>9.3</b> Positive and null recurrence</a></li>
<li class="chapter" data-level="9.4" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-strong-markov"><i class="fa fa-check"></i><b>9.4</b> Strong Markov property</a></li>
<li class="chapter" data-level="9.5" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-lemma"><i class="fa fa-check"></i><b>9.5</b> A useful lemma</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html"><i class="fa fa-check"></i><b>10</b> Stationary distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#def-stationary-definition"><i class="fa fa-check"></i><b>10.1</b> Definition of stationary distribution</a></li>
<li class="chapter" data-level="10.2" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#find-stationary"><i class="fa fa-check"></i><b>10.2</b> Finding a stationary distribution</a></li>
<li class="chapter" data-level="10.3" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#exist-unique"><i class="fa fa-check"></i><b>10.3</b> Existence and uniqueness</a></li>
<li class="chapter" data-level="10.4" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#stat-proof"><i class="fa fa-check"></i><b>10.4</b> Proof of existence and uniqueness</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem sheet 5</a></li>
<li class="chapter" data-level="11" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html"><i class="fa fa-check"></i><b>11</b> Long-term behaviour of Markov chains</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#equilibrium"><i class="fa fa-check"></i><b>11.1</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="11.2" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#convergence-examples"><i class="fa fa-check"></i><b>11.2</b> Examples of convergence and non-convergence</a></li>
<li class="chapter" data-level="11.3" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-ergodic"><i class="fa fa-check"></i><b>11.3</b> Ergodic theorem</a></li>
<li class="chapter" data-level="11.4" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-proofs"><i class="fa fa-check"></i><b>11.4</b> Proofs of the limit and ergodic theorems</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S12-revision-i.html"><a href="S12-revision-i.html"><i class="fa fa-check"></i><b>12</b> End of of Part I: Discrete time Markov chains</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-revision-i.html"><a href="S12-revision-i.html#todo-revision"><i class="fa fa-check"></i><b>12.1</b> Things to do</a></li>
<li class="chapter" data-level="12.2" data-path="S12-revision-i.html"><a href="S12-revision-i.html#summary-i"><i class="fa fa-check"></i><b>12.2</b> Summary of Part 1</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P06.html"><a href="P06.html"><i class="fa fa-check"></i>Problem sheet 6</a></li>
<li class="chapter" data-level="" data-path="A3.html"><a href="A3.html"><i class="fa fa-check"></i>Assessment 3</a></li>
<li class="part"><span><b>Part II: Continuous time Markov jump processes</b></span></li>
<li class="chapter" data-level="13" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html"><i class="fa fa-check"></i><b>13</b> Poisson process with Poisson increments</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-dist"><i class="fa fa-check"></i><b>13.1</b> Poisson distribution</a></li>
<li class="chapter" data-level="13.2" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-def-poisson"><i class="fa fa-check"></i><b>13.2</b> Definition 1: Poisson increments</a></li>
<li class="chapter" data-level="13.3" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#summed-marked"><i class="fa fa-check"></i><b>13.3</b> Summed and marked Poisson processes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html"><i class="fa fa-check"></i><b>14</b> Poisson process with exponential holding times</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#exponential"><i class="fa fa-check"></i><b>14.1</b> Exponential distribution</a></li>
<li class="chapter" data-level="14.2" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#definition-2-exponential-holding-times"><i class="fa fa-check"></i><b>14.2</b> Definition 2: exponential holding times</a></li>
<li class="chapter" data-level="14.3" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#cont-markov"><i class="fa fa-check"></i><b>14.3</b> Markov property in continuous time</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P07.html"><a href="P07.html"><i class="fa fa-check"></i>Problem sheet 7</a></li>
<li class="chapter" data-level="15" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html"><i class="fa fa-check"></i><b>15</b> Poisson process in infinitesimal time periods</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#infinitesimal"><i class="fa fa-check"></i><b>15.1</b> Definition 3: increments in infinitesimal time</a></li>
<li class="chapter" data-level="15.2" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#sum2"><i class="fa fa-check"></i><b>15.2</b> Example: sum of two Poisson processes</a></li>
<li class="chapter" data-level="15.3" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#forward"><i class="fa fa-check"></i><b>15.3</b> Forward equations and proof of equivalence</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html"><i class="fa fa-check"></i><b>16</b> Counting processes</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html#birth-processes"><i class="fa fa-check"></i><b>16.1</b> Birth processes</a></li>
<li class="chapter" data-level="16.2" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html#TIPP"><i class="fa fa-check"></i><b>16.2</b> Time inhomogeneous Poisson process</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P08.html"><a href="P08.html"><i class="fa fa-check"></i>Problem Sheet 8</a></li>
<li class="chapter" data-level="17" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html"><i class="fa fa-check"></i><b>17</b> Continuous time Markov jump processes</a>
<ul>
<li class="chapter" data-level="17.1" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#jump-holding"><i class="fa fa-check"></i><b>17.1</b> Jump chain and holding times</a></li>
<li class="chapter" data-level="17.2" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#CTMC-examples"><i class="fa fa-check"></i><b>17.2</b> Examples</a></li>
<li class="chapter" data-level="17.3" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#explosion"><i class="fa fa-check"></i><b>17.3</b> A brief note on explosion</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html"><i class="fa fa-check"></i><b>18</b> Forward and backward equations</a>
<ul>
<li class="chapter" data-level="18.1" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#jump-infinitesimal"><i class="fa fa-check"></i><b>18.1</b> Transitions in infinitesimal time periods</a></li>
<li class="chapter" data-level="18.2" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#semigroup"><i class="fa fa-check"></i><b>18.2</b> Transition semigroup and the forward and backward equations</a></li>
<li class="chapter" data-level="18.3" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#matrix-exp"><i class="fa fa-check"></i><b>18.3</b> Matrix exponential</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P09.html"><a href="P09.html"><i class="fa fa-check"></i>Problem Sheet 9</a></li>
<li class="chapter" data-level="19" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html"><i class="fa fa-check"></i><b>19</b> Class structure and hitting times</a>
<ul>
<li class="chapter" data-level="19.1" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#classes-cont"><i class="fa fa-check"></i><b>19.1</b> Communicating classes</a></li>
<li class="chapter" data-level="19.2" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#periods2"><i class="fa fa-check"></i><b>19.2</b> A brief note on periodicity</a></li>
<li class="chapter" data-level="19.3" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#hitting2"><i class="fa fa-check"></i><b>19.3</b> Hitting probabilities and expected hitting times</a></li>
<li class="chapter" data-level="19.4" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#recurrence-transience2"><i class="fa fa-check"></i><b>19.4</b> Recurrence and transience</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html"><i class="fa fa-check"></i><b>20</b> Long-term behaviour of Markov jump procceses</a>
<ul>
<li class="chapter" data-level="20.1" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#stationary-jump"><i class="fa fa-check"></i><b>20.1</b> Stationary distributions</a></li>
<li class="chapter" data-level="20.2" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#convergernce-cont"><i class="fa fa-check"></i><b>20.2</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="20.3" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#ergodic-cont"><i class="fa fa-check"></i><b>20.3</b> Ergodic theorem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P10.html"><a href="P10.html"><i class="fa fa-check"></i>Problem Sheet 10</a></li>
<li class="chapter" data-level="" data-path="A4.html"><a href="A4.html"><i class="fa fa-check"></i>Assessment 4</a></li>
<li class="chapter" data-level="21" data-path="S21-queues.html"><a href="S21-queues.html"><i class="fa fa-check"></i><b>21</b> Queues</a></li>
<li class="chapter" data-level="22" data-path="S22-end.html"><a href="S22-end.html"><i class="fa fa-check"></i><b>22</b> Last things</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html"><i class="fa fa-check"></i>Computational worksheets</a>
<ul>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#C-about"><i class="fa fa-check"></i>About the computational worksheets</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#R-access"><i class="fa fa-check"></i>How to access R</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#R-background"><i class="fa fa-check"></i>R background</a></li>
</ul></li>
<li class="divider"></li>
<li></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2750 Introduction to Markov Processes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="P03" class="section level1 unnumbered">
<h1>Problem sheet 3</h1>
<style>
.fold-btn { 
  float: right; 
  margin: -12px 0 0 0;
}
</style>
<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".myanswers");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Show solution</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");  // if the text equals "Fold", change it to "Unfold"or else to "Fold" 
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>
<!--
<style>
.myanswers { 
display: none !important;
}
</style>
-->
<div class="mysummary">
<p>You should attempt all these questions and write up your solutions in advance of your workshop in week 4 (Monday 15 or Tuesday 16 February) where the answers will be discussed.</p>
</div>
<div class="myq">
<p><strong>1.</strong> Consider a Markov chain with state space <span class="math inline">\(\mathcal S = \{1,2,3\}\)</span>, and transition matrix partially given by
<span class="math display">\[ \mathsf P = \begin{pmatrix} ? &amp; 0.3 &amp; 0.3 \\ 0.2 &amp; 0.4 &amp; ? \\ ? &amp; ? &amp; 1 \end{pmatrix} . \]</span></p>
<div class="subq">
<p><strong>(a)</strong> Replace the four question marks by the appropriate transition probabilities.</p>
<div class="myanswers">
<p><em>Solution.</em> Rows must add up to 1 and every entry must be non-negative, so the transition matrix is
<span class="math display">\[ \mathsf P = \begin{pmatrix} 0.4 &amp; 0.3 &amp; 0.3 \\ 0.2 &amp; 0.4 &amp; 0.4 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} . \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> Draw a transition diagram for this Markov chain.</p>
<div class="myanswers">
<p><em>Solution.</em></p>
<div class="figure" style="text-align: center"><span id="fig:Q31"></span>
<img src="math2750_files/figure-html/Q31-1.png" alt="Transition diagram for Question 1." width="384" />
<p class="caption">
Figure 6.3: Transition diagram for Question 1.
</p>
</div>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> Find the matrix <span class="math inline">\(\mathsf P(2)\)</span> of two-step transition probabilities.</p>
<div class="myanswers">
<p><em>Solution.</em> <span class="math inline">\({\displaystyle \mathsf P(2) = \mathsf P^2 = \begin{pmatrix} 0.22 &amp; 0.24 &amp; 0.54 \\ 0.16 &amp; 0.22 &amp; 0.62 \\ 0 &amp; 0 &amp; 1 \end{pmatrix}}\)</span></p>
</div>
</div>
<div class="subq">
<p><strong>(d)</strong> By summing the probabilities of all relevant paths, find the three-step transition probability <span class="math inline">\(p_{13}(3)\)</span>.</p>
<div class="myanswers">
<p><em>Solution.</em> There are seven relevant paths: <span class="math inline">\(1 \to 1 \to 1 \to 3\)</span>, <span class="math inline">\(1 \to 1 \to 2 \to 3\)</span>, <span class="math inline">\(1 \to 1 \to 3 \to 3\)</span>, <span class="math inline">\(1 \to 2 \to 1 \to 3\)</span>, <span class="math inline">\(1 \to 2 \to 2 \to 3\)</span>, <span class="math inline">\(1 \to 2 \to 3 \to 3\)</span>, and <span class="math inline">\(1 \to 3 \to 3 \to 3\)</span>. So
<span class="math display">\[\begin{align*}
p_{13}(3) &amp;= p_{11}p_{11}p_{11}p_{13} + p_{11}p_{12}p_{23} + p_{11}p_{13}p_{33}  + p_{12} p_{21} p_{13}\\
&amp; \qquad{}+ p_{12}p_{22}p_{23} + p_{12}p_{23}p_{33} + p_{13}p_{33}p_{33}\\
&amp; = 0.4 \cdot 0.4 \cdot 0.3 + 0.4\cdot 0.3\cdot 0.4 + 0.4\cdot 0.3 \cdot 1 + 0.3 \cdot 0.2 \cdot 0.3 \\
&amp; \qquad{}+ 0.3\cdot 0.4 \cdot 0.4 + 0.3 \cdot 0.4 \cdot 1 + 0.3 \cdot 1 \cdot 1\\
&amp;= 0.702
\end{align*}\]</span></p>
</div>
</div>
</div>
<div style="display: flex;">
<div>
<div class="myq">
<p><strong>2.</strong> Consider a Markov chain <span class="math inline">\((X_n)\)</span> which moves between the vertices of
a tetrahedron.</p>
<p>At each time step, the process randomly chooses one of the edges connected to the current vertex and follows it to a new vertex. The edge to follow is selected randomly with all options having equal probability and each selection is independent of the past movements. Let <span class="math inline">\(X_n\)</span> be the vertex the process is in after step <span class="math inline">\(n\)</span>.</p>
<div class="subq">
<p><strong>(a)</strong> Write down the transition matrix <span class="math inline">\(\mathsf P\)</span> of this Markov chain.</p>
<div class="myanswers">
<p>The chain can move from a state to any of the other <span class="math inline">\(3\)</span> states, each with probability <span class="math inline">\(1/3\)</span>. So
<span class="math display">\[ \mathsf P = \begin{pmatrix} 0 &amp; \frac13 &amp; \frac13 &amp; \frac13 \\
                               \frac13 &amp; 0 &amp; \frac13 &amp; \frac13 \\
                               \frac13 &amp; \frac13 &amp; 0 &amp; \frac13 \\
                               \frac13 &amp; \frac13 &amp; \frac13 &amp; 0 \end{pmatrix} . \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> By summing over all relevant paths of length two, calculate the two-step transition probabilities <span class="math inline">\(p_{11}(2)\)</span> and <span class="math inline">\(p_{12}(2)\)</span>. Hence, write down the two-step transition matrix <span class="math inline">\(\mathsf P(2)\)</span>.</p>
<div class="myanswers">
<p>The length-2 paths from 1 to 1 are <span class="math inline">\(1 \to k \to 1\)</span> for <span class="math inline">\(k = 2,3,4\)</span>, so
<span class="math display">\[ p_{11}(2) = p_{12}p_{21} + p_{13}p_{31} + p_{14}p_{41} = \tfrac13 \tfrac13 +  \tfrac13 \tfrac13 + \tfrac13 \tfrac13 = \tfrac13  .   \]</span>
The length-2 paths from 1 to 2 are <span class="math inline">\(1 \to 3 \to 2\)</span> and <span class="math inline">\(1 \to 4 \to 2\)</span>, so
<span class="math display">\[ p_{12}(2) = p_{13}p_{32} + p_{14}p_{42} = \tfrac13 \tfrac13 + \tfrac13 \tfrac13 = \tfrac29 . \]</span></p>
<p>By symmetry, <span class="math inline">\(p_{ii}(2) = p_{11}(2)\)</span> for all <span class="math inline">\(i\)</span>, and <span class="math inline">\(p_{ij}(2) = p_{12}(2)\)</span> for all <span class="math inline">\(i \neq j\)</span>. Therefore
<span class="math display">\[ \mathsf P(2) = \begin{pmatrix} \frac13 &amp; \frac29 &amp; \frac29 &amp; \frac29 \\
                               \frac29 &amp; \frac13 &amp; \frac29 &amp; \frac29 \\
                               \frac29 &amp; \frac29 &amp; \frac13 &amp; \frac29 \\
                               \frac29 &amp; \frac29 &amp; \frac29 &amp; \frac13 \end{pmatrix} . \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> Check your answer by calculating the matrix square <span class="math inline">\(\mathsf P^2\)</span>.</p>
<div class="myanswers">
<p>We can verify that
<span class="math display">\[ \mathsf P^2 = \begin{pmatrix} 0 &amp; \frac13 &amp; \frac13 &amp; \frac13 \\
\frac13 &amp; 0 &amp; \frac13 &amp; \frac13 \\
\frac13 &amp; \frac13 &amp; 0 &amp; \frac13 \\
\frac13 &amp; \frac13 &amp; \frac13 &amp; 0 \end{pmatrix} \begin{pmatrix} 0 &amp; \frac13 &amp; \frac13 &amp; \frac13 \\
\frac13 &amp; 0 &amp; \frac13 &amp; \frac13 \\
\frac13 &amp; \frac13 &amp; 0 &amp; \frac13 \\
\frac13 &amp; \frac13 &amp; \frac13 &amp; 0 \end{pmatrix}=
\begin{pmatrix} \frac13 &amp; \frac29 &amp; \frac29 &amp; \frac29 \\
\frac29 &amp; \frac13 &amp; \frac29 &amp; \frac29 \\
\frac29 &amp; \frac29 &amp; \frac13 &amp; \frac29 \\
\frac29 &amp; \frac29 &amp; \frac29 &amp; \frac13 \end{pmatrix} , \]</span>
as above.</p>
</div>
</div>
</div>
</div>
<div>
<div class="figure" style="text-align: center"><span id="fig:testing"></span>
<img src="math2750_files/figure-html/testing-1.png" alt="A tetrahedron" width="850em" />
<p class="caption">
Figure 6.4: A tetrahedron
</p>
</div>
</div>
</div>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/E3qMZ6gRA0k">
</iframe>
</div>
</div>
<div class="myq">
<p><strong>3.</strong> Consider the two-state “broken printer” Markov chain, with state space <span class="math inline">\(\mathcal S = \{0,1\}\)</span>, transition matrix
<span class="math display">\[ \mathsf P = \begin{pmatrix} 1-\alpha &amp; \alpha \\
                 \beta &amp; 1-\beta \end{pmatrix} \]</span>
with <span class="math inline">\(0 &lt; \alpha, \beta &lt; 1\)</span>, and initial distribution <span class="math inline">\(\boldsymbol\lambda = (\lambda_0, \lambda_1)\)</span>. Write <span class="math inline">\(\mu_n =\mathbb P(X_n = 0)\)</span>.</p>
<div class="subq">
<p><strong>(a)</strong> By writing <span class="math inline">\(\mu_{n+1}\)</span> in terms of <span class="math inline">\(\mu_n\)</span>, show that we have
<span class="math display">\[ \mu_{n+1} - \big(1-(\alpha+\beta)\big)\mu_n = \beta . \]</span></p>
<div class="myanswers">
<p>Using the law of total probability, we have
<span class="math display">\[\begin{multline*}
\mathbb P(X_{n+1} = 0) = \mathbb P(X_n = 0)\,\mathbb P(X_{n+1} = 0 \mid X_n = 0) \\
+ \mathbb P(X_n = 1)\,\mathbb P(X_{n+1} = 0 \mid X_n = 1) ,
\end{multline*}\]</span>
which in terms of <span class="math inline">\((\mu_n)\)</span> is
<span class="math display">\[ \mu_{n+1} = \mu_n (1-\alpha) + (1 - \mu_n)\beta . \]</span>
We used here that <span class="math inline">\(\mathbb P(X_n = 1) = 1-\mu_n\)</span>.
Rearranging this gives the answer.</p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> By solving this linear difference equation using the initial condition <span class="math inline">\(\mu_0 = \lambda_0\)</span>, or otherwise, show that
<span class="math display">\[ \mu_n = \frac{\beta}{\alpha+\beta} + \left(\lambda_0 - \frac{\beta}{\alpha+\beta}\right)\big(1-(\alpha+\beta)\big)^n   . \]</span></p>
<div class="myanswers">
<p>The characteristic equation is <span class="math inline">\(\lambda - (1-(\alpha+\beta)) = 0\)</span> with a single root at <span class="math inline">\(\lambda = 1 - (\alpha+\beta)\)</span>. The general solution to the homogeneous equation is, therefore, <span class="math inline">\(A(1-(\alpha+\beta))^n\)</span>.</p>
<p>For a particular solution, we guess a solution <span class="math inline">\(\mu_n = C\)</span>, and <span class="math inline">\(C - (1-(\alpha+\beta))C = \beta\)</span> gives <span class="math inline">\(C = \beta/(\alpha+\beta)\)</span>. Thus the general solution to the inhomogeneous equation is
<span class="math display">\[ \mu_n = \frac{\beta}{\alpha+\beta} + A\big(1-(\alpha+\beta)\big)^n .\]</span></p>
<p>From the initial condition, we get <span class="math inline">\(\lambda_0 = \beta/(\alpha+\beta) + A\)</span>, and therefore <span class="math inline">\(A = \lambda_0 - \beta/(\alpha+\beta)\)</span>. The solution is therefore as given.</p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> What, therefore, are <span class="math inline">\(\lim_{n\to\infty} \mathbb P(X_n = 0)\)</span> and <span class="math inline">\(\lim_{n\to\infty} \mathbb P(X_n = 1)\)</span>?</p>
<div class="myanswers">
<p>Note that <span class="math inline">\(-1 &lt; 1 - (\alpha + \beta) &lt; 1\)</span>, so <span class="math inline">\((1-(\alpha+\beta))^n \to 0\)</span>. Therefore we have
<span class="math display">\[\begin{align*}
\lim_{n\to\infty} \mathbb P(X_n = 0) &amp;= \lim_{n\to\infty} \mu_n \\
&amp;= \lim_{n\to\infty} \left( \frac{\beta}{\alpha+\beta} + \left(\lambda_0 - \frac{\beta}{\alpha+\beta}\right)\big(1-(\alpha+\beta)\big)^n \right) \\
&amp;= \frac{\beta}{\alpha+\beta} .
\end{align*}\]</span>
Since <span class="math inline">\(\mathbb P(X_n = 1) = 1- \mathbb P(X_n = 0)\)</span>, we have
<span class="math display">\[ \mathbb P(X_n = 1) \to 1 - \frac{\beta}{\alpha+\beta} = \frac{\alpha}{\alpha+\beta} . \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(d)</strong> Explain what happens if the Markov chain is started in the distribution
<span class="math display">\[ \lambda_0 = \frac{\beta}{\alpha+\beta} , \qquad \lambda_1 = \frac{\alpha}{\alpha+\beta}  . \]</span></p>
<div class="myanswers">
<p>Substituting in the value of <span class="math inline">\(\lambda_0\)</span> into the equation for <span class="math inline">\(\mu_n\)</span>, the second term cancel, and we have that <span class="math inline">\(\mathbb P(X_n = 0) = \mu_n = \beta/(\alpha+\beta)\)</span> for all times <span class="math inline">\(n\)</span>, and therefor <span class="math inline">\(\mathbb P(X_n = 1) = \alpha/(\alpha+\beta)\)</span> too. This means that the Markov chain remains in the same “stationary distribution” forever.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>4.</strong> Let <span class="math inline">\((X_n)\)</span> be a Markov chain. Show that, for any <span class="math inline">\(m \geq 1\)</span>, we have
<span class="math display">\[ \mathbb P(X_{n+m} = x_{n+m} \mid X_n = x_n, X_{n-1} = x_{n-1}, \dots, X_0 = x_0)  =  \mathbb P(X_{n+m} = x_{n+m} \mid X_n = x_n) . \]</span></p>
<div class="myanswers">
<p>Note that we have a sequence of statements here, for <span class="math inline">\(m = 1, 2, \dots\)</span>. Note also that the case <span class="math inline">\(m = 1\)</span> is the standard Markov property. When we have a sequence of statements and we can easily prove the first one, this is a good sign that a proof by induction is the way to go.</p>
<p>Before starting, for reasons of space, we adopt notation where we suppress the capital <span class="math inline">\(X\)</span>s, so we want to show that
<span class="math display">\[ \mathbb P(x_{n+m} \mid x_n, x_{n-1}, \dots, x_0 ) = \mathbb P(x_{n+m} \mid x_n) . \]</span></p>
<p>We work by induction on <span class="math inline">\(m\)</span>. The base case <span class="math inline">\(m = 1\)</span> is the standard Markov property.</p>
<p>Assume the inductive hypothesis: that result holds for <span class="math inline">\(m\)</span>. We now need to prove the inductive step: that the result holds for <span class="math inline">\(m+1\)</span>. For <span class="math inline">\(m+1\)</span> we have, by conditioning on the first step <span class="math inline">\(x_{n+1}\)</span>,
<span class="math display">\[\begin{multline*} \mathbb P(x_{n+m+1} \mid x_n, x_{n-1}, \dots, x_0 ) \\
 = \sum_{x_{n+1}} \mathbb P(x_{n+1} \mid x_n, x_{n-1}, \dots, x_0 )\,\mathbb P(x_{n+m+1} \mid x_{n+1}, x_n, x_{n-1}, \dots, x_0 )     \end{multline*}\]</span>
By the standard Markov property the first term simplifies to <span class="math inline">\(\mathbb P(x_{n+1} \mid x_n)\)</span>, and by the result for <span class="math inline">\(m\)</span> the second term simplifies to <span class="math inline">\(\mathbb P(x_{n+m+1} \mid x_{n+1})\)</span>. So we have
<span class="math display">\[ \mathbb P(x_{n+m+1} \mid x_n, x_{n-1}, \dots, x_0 ) = \sum_{x_{n+1}} \mathbb P(x_{n+1} \mid x_n) \mathbb P(x_{n+m+1} \mid x_{n+1}) . \]</span>
But the right-hand side here is <span class="math inline">\(\mathbb P(x_{n+m+1} \mid x_n)\)</span> written using conditioning on the first step and using the result for <span class="math inline">\(m\)</span>. By induction, we are done.</p>
</div>
</div>
<div class="myq">
<p><strong>5.</strong> A car insurance company operates a no-claims discount system for existing policy holders. The possible discounts on premiums are <span class="math inline">\(\{0\%,25\%,40\%,50\%\}\)</span>. Following a claim-free year, a policyholder’s discount level increases by one level (or remains at 50% discount). If the policyholder makes one or more claims in a year, the discount level decreases by one level (or remains at 0% discount).</p>
<p>The insurer believes that the probability of of making at least one claim in a year is <span class="math inline">\(0.1\)</span> if the previous year was claim-free and <span class="math inline">\(0.25\)</span> if the previous year was not claim-free.</p>
<div class="subq">
<p><strong>(a)</strong> Explain why we cannot use <span class="math inline">\(\{0\%,25\%,40\%,50\%\}\)</span> as the state space of a Markov chain to model discount levels for policyholders.</p>
<div class="myanswers">
<p>The Markov property does not hold for the time-homogeneous process described since the probability of moving to a given state at the next time step is not simply dependent on the current state if <span class="math inline">\(\mathcal S=\{0\%,25\%,40\%,50\%\}\)</span>. For example,
<span class="math display">\[
    \mathbb P(X_{n+1}=25\% \mid X_n= 40\% )=\begin{cases} 
    0.25 &amp; \text{if $X_{n-1}=50\%$}\\
    0.1 &amp; \text{if $X_{n-1}=25\%$.} \end{cases} \]</span></p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> By considering additional states, show that a Markov chain can be used to model the discount level.</p>
<div class="myanswers">
<p>The problem is that the process has a memory of the previous year.
If we currently have a discount of 0%, we know a claim was made in the year before, so no changes are required. Similarly, at 50% discount, we know that no claim was made in the previous year. The other two states, 25% and 40%, have different behaviour depending on whether or not there was a claim in the previous year.</p>
<p>So we will split each of these into two states: 25+ will denote a 25% discount with no claim in the previous year, while 25- will denote a 25% discount with a claim in the previous year. We define the state 40+ and 40- similarly. Then we have a Markov chain, since the current state and the number of claims in the previous year completely defines the distribution on future behaviour.</p>
</div>
</div>
<div class="subq">
<p><strong>(c)</strong> Draw the transition diagram and write down the transition matrix.</p>
<div class="myanswers">
<p>The transition diagram is as shown below.</p>
<div class="figure" style="text-align: center"><span id="fig:fortyplus"></span>
<img src="math2750_files/figure-html/fortyplus-1.png" alt="Transition diagram for the car insurance Markov chain" width="480" />
<p class="caption">
Figure 6.5: Transition diagram for the car insurance Markov chain
</p>
</div>
<p>The transition matrix is given by,
<span class="math display">\[ \mathsf P = 
    \begin{matrix}
    &amp; \begin{matrix} 
        0 &amp; 25+ &amp; 25- &amp; 40+ &amp; 40- &amp; 50
      \end{matrix} \\
    \begin{matrix}
      0 \\ 25+ \\ 25- \\ 40+ \\ 40- \\ 50
    \end{matrix}
    &amp;
    \begin{pmatrix}
    0.25 &amp; 0.75 &amp; 0    &amp; 0    &amp; 0   &amp; 0    \\
      0.1  &amp; 0    &amp; 0    &amp; 0.9  &amp; 0   &amp; 0    \\
      0.25 &amp; 0    &amp; 0    &amp; 0.75 &amp; 0   &amp; 0    \\
      0    &amp; 0    &amp; 0.1  &amp; 0    &amp; 0   &amp; 0.9  \\
      0    &amp; 0    &amp; 0.25 &amp; 0    &amp; 0   &amp; 0.75 \\
      0    &amp; 0    &amp; 0    &amp; 0    &amp; 0.1 &amp; 0.9 
    \end{pmatrix}
    \end{matrix}
    \]</span></p>
</div>
</div>
</div>
<div class="myq">
<p><strong>6.</strong> The credit rating of a company can be modelled as a Markov chain. Assume the rating is assessed once per year at the end of the year and possible ratings are A (good), B (fair) and D (in default). The transition matrix is
<span class="math display">\[\mathsf P=\begin{pmatrix} 0.92&amp;0.05&amp;0.03\\
0.05&amp;0.85&amp;0.1\\
0&amp;0&amp;1 \end{pmatrix} . \]</span></p>
<div class="subq">
<p><strong>(a)</strong> Calculate the two-step transition probabilities, and hence find the expected number of defaults in the next two years from <span class="math inline">\(100\)</span> companies all rated A at the start of the period.</p>
<div class="myanswers">
<p>The matrix of two-step transition probabilities is given by the matrix square
<span class="math display">\[\mathsf P(2) = \mathsf P^2= \begin{pmatrix} 0.8489&amp;0.0885&amp;0.0626\\
0.0885&amp;0.7250&amp;0.1865\\
0&amp;0&amp;1 \end{pmatrix}. \]</span>
The number of defaults in two years from <span class="math inline">\(100\)</span> A-rated companies is <span class="math inline">\(100 \times p_{\mathrm{AD}}(2) = 100 \times 0.0626 = 6.26\)</span>.</p>
</div>
</div>
<div class="subq">
<p><strong>(b)</strong> What is the probability that a company rated A will at some point default without ever having been rated B in the meantime?</p>
<div class="myanswers">
<p>Let <span class="math inline">\(\delta\)</span> be the desired probability that an A-rated company will default without having been rated B. We condition on the first step: with probability <span class="math inline">\(0.92\)</span> we remain in state A, and by the Markov property the probability of the given event remains at <span class="math inline">\(\delta\)</span>; with probability <span class="math inline">\(0.05\)</span> we move to state B, and the event fails to occur; and with probability <span class="math inline">\(0.03\)</span> we move to state D and the event occurs immediately. Therefore, we have
<span class="math display">\[ \delta = 0.92\delta + 0.05\times 0 + 0.03 \times 1 = 0.92\delta + 0.03 ,  \]</span>
which has solution <span class="math inline">\(\delta = 0.03/(1-0.92) = 0.375\)</span>.</p>
</div>
</div>
<p>A corporate bond portfolio manager follows an investment strategy which means that bonds which fall from A-rated to B-rated are sold and replaced with an A-rated bond. The manager believes this will improve the returns on the portfolio because it will reduce the number of defaults experienced.</p>
<div class="subq">
<p><strong>(c)</strong> Calculate the expected number of defaults in the manager’s portfolio over the next two years given there are initially 100 A-rated bonds.</p>
<div class="myanswers">
<p>Given that B-rated bonds are replaced by A-rated bonds, we have a new Markov chain with state space <span class="math inline">\(\{\mathrm{A},\mathrm{D}\}\)</span> and transition matrix
<span class="math display">\[ \mathsf P = \begin{pmatrix} 0.92+0.05 &amp; 0.03 \\ 0 &amp; 1 \end{pmatrix} =  \begin{pmatrix} 0.97 &amp; 0.03 \\ 0 &amp; 1 \end{pmatrix} .  \]</span>
The two-step transition probability is
<span class="math display">\[ \mathsf P(2) = \mathsf P^2 =  \begin{pmatrix} 0.97 &amp; 0.03 \\ 0 &amp; 1 \end{pmatrix} \begin{pmatrix} 0.97 &amp; 0.03 \\ 0 &amp; 1 \end{pmatrix} = \begin{pmatrix} 0.9409 &amp; 0.0591 \\ 0 &amp; 1 \end{pmatrix} .  \]</span>
Thus the number of defaults from <span class="math inline">\(100\)</span> A-rated bonds in two years is <span class="math inline">\(100\times p_{\mathrm{AD}}(2) = 100\times 0.0591 = 5.91\)</span>. The manager was right: this is slightly less than the <span class="math inline">\(6.26\)</span> from part (a).</p>
</div>
</div>
</div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="S06-examples.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="S07-classes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math2750.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

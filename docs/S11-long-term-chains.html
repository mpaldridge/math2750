<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 11 Long-term behaviour of Markov chains | MATH2750 Introduction to Markov Processes</title>
  <meta name="description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 11 Long-term behaviour of Markov chains | MATH2750 Introduction to Markov Processes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://mpaldridge.github.io/math2750/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 11 Long-term behaviour of Markov chains | MATH2750 Introduction to Markov Processes" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH2750 Introduction to Markov Process at the University of Leeds, 2020–2021" />
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="P05.html"/>
<link rel="next" href="S12-revision-i.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH2750 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-module"><i class="fa fa-check"></i>Organisation of MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-computing"><i class="fa fa-check"></i>Computing worksheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#dropin"><i class="fa fa-check"></i>Drop-in sessions</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#team"><i class="fa fa-check"></i>Microsoft Team</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#time"><i class="fa fa-check"></i>Time management</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#exam"><i class="fa fa-check"></i>Exam</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#ask"><i class="fa fa-check"></i>Who should I ask about…?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#about-content"><i class="fa fa-check"></i>Content of MATH2750</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#prereqs"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#books"><i class="fa fa-check"></i>Books</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#finally"><i class="fa fa-check"></i>And finally…</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Discrete time Markov chains</b></span></li>
<li class="chapter" data-level="1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html"><i class="fa fa-check"></i><b>1</b> Stochastic processes and the Markov property</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#models"><i class="fa fa-check"></i><b>1.1</b> Deterministic and random models</a></li>
<li class="chapter" data-level="1.2" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#stochastic-processes"><i class="fa fa-check"></i><b>1.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="1.3" data-path="S01-stochastic-processes.html"><a href="S01-stochastic-processes.html#markov-property"><i class="fa fa-check"></i><b>1.3</b> Markov property</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-random-walk.html"><a href="S02-random-walk.html"><i class="fa fa-check"></i><b>2</b> Random walk</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-random-walk.html"><a href="S02-random-walk.html#simple-random-walk"><i class="fa fa-check"></i><b>2.1</b> Simple random walk</a></li>
<li class="chapter" data-level="2.2" data-path="S02-random-walk.html"><a href="S02-random-walk.html#general-random-walks"><i class="fa fa-check"></i><b>2.2</b> General random walks</a></li>
<li class="chapter" data-level="2.3" data-path="S02-random-walk.html"><a href="S02-random-walk.html#exact-distribution"><i class="fa fa-check"></i><b>2.3</b> Exact distribution of the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html"><i class="fa fa-check"></i><b>3</b> Gambler’s ruin</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-chain"><i class="fa fa-check"></i><b>3.1</b> Gambler’s ruin Markov chain</a></li>
<li class="chapter" data-level="3.2" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#ruin-probability"><i class="fa fa-check"></i><b>3.2</b> Probability of ruin</a></li>
<li class="chapter" data-level="3.3" data-path="S03-gamblers-ruin.html"><a href="S03-gamblers-ruin.html#expected-duration"><i class="fa fa-check"></i><b>3.3</b> Expected duration of the game</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-ldes.html"><a href="S04-ldes.html"><i class="fa fa-check"></i><b>4</b> Linear difference equations</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-ldes.html"><a href="S04-ldes.html#hom-ldes"><i class="fa fa-check"></i><b>4.1</b> Homogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.2" data-path="S04-ldes.html"><a href="S04-ldes.html#ruin-probability-solve"><i class="fa fa-check"></i><b>4.2</b> Probability of ruin for the gambler’s ruin</a></li>
<li class="chapter" data-level="4.3" data-path="S04-ldes.html"><a href="S04-ldes.html#inhom-ldes"><i class="fa fa-check"></i><b>4.3</b> Inhomogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.4" data-path="S04-ldes.html"><a href="S04-ldes.html#duration-solve"><i class="fa fa-check"></i><b>4.4</b> Expected duration for the gambler’s ruin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem sheet 2</a></li>
<li class="chapter" data-level="" data-path="A1.html"><a href="A1.html"><i class="fa fa-check"></i>Assessment 1</a></li>
<li class="chapter" data-level="5" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html"><i class="fa fa-check"></i><b>5</b> Discrete time Markov chains</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#thmc"><i class="fa fa-check"></i><b>5.1</b> Time homogeneous discrete time Markov chains</a></li>
<li class="chapter" data-level="5.2" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#S05-example"><i class="fa fa-check"></i><b>5.2</b> A two-state example</a></li>
<li class="chapter" data-level="5.3" data-path="S05-markov-chains.html"><a href="S05-markov-chains.html#n-step"><i class="fa fa-check"></i><b>5.3</b> <em>n</em>-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-examples.html"><a href="S06-examples.html"><i class="fa fa-check"></i><b>6</b> Examples from actuarial science</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-examples.html"><a href="S06-examples.html#S06-example1"><i class="fa fa-check"></i><b>6.1</b> A simple no-claims discount model</a></li>
<li class="chapter" data-level="6.2" data-path="S06-examples.html"><a href="S06-examples.html#S06-example2"><i class="fa fa-check"></i><b>6.2</b> An accident model with memory</a></li>
<li class="chapter" data-level="6.3" data-path="S06-examples.html"><a href="S06-examples.html#S06-example3"><i class="fa fa-check"></i><b>6.3</b> A no-claims discount model with memory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem sheet 3</a></li>
<li class="chapter" data-level="7" data-path="S07-classes.html"><a href="S07-classes.html"><i class="fa fa-check"></i><b>7</b> Class structure</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-classes.html"><a href="S07-classes.html#comm-classes"><i class="fa fa-check"></i><b>7.1</b> Communicating classes</a></li>
<li class="chapter" data-level="7.2" data-path="S07-classes.html"><a href="S07-classes.html#periodicity"><i class="fa fa-check"></i><b>7.2</b> Periodicity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html"><i class="fa fa-check"></i><b>8</b> Hitting times</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#hitting-definitions"><i class="fa fa-check"></i><b>8.1</b> Hitting probabilities and expected hitting times</a></li>
<li class="chapter" data-level="8.2" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-times"><i class="fa fa-check"></i><b>8.2</b> Return times</a></li>
<li class="chapter" data-level="8.3" data-path="S08-hitting-times.html"><a href="S08-hitting-times.html#return-rw"><i class="fa fa-check"></i><b>8.3</b> Hitting and return times for the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem sheet 4</a></li>
<li class="chapter" data-level="9" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html"><i class="fa fa-check"></i><b>9</b> Recurrence and transience</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-trans-def"><i class="fa fa-check"></i><b>9.1</b> Recurrent and transient states</a></li>
<li class="chapter" data-level="9.2" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#rec-tran-classes"><i class="fa fa-check"></i><b>9.2</b> Recurrent and transient classes</a></li>
<li class="chapter" data-level="9.3" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-positive-null"><i class="fa fa-check"></i><b>9.3</b> Positive and null recurrence</a></li>
<li class="chapter" data-level="9.4" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-strong-markov"><i class="fa fa-check"></i><b>9.4</b> Strong Markov property</a></li>
<li class="chapter" data-level="9.5" data-path="S09-recurrence-transience.html"><a href="S09-recurrence-transience.html#S09-lemma"><i class="fa fa-check"></i><b>9.5</b> A useful lemma</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html"><i class="fa fa-check"></i><b>10</b> Stationary distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#def-stationary-definition"><i class="fa fa-check"></i><b>10.1</b> Definition of stationary distribution</a></li>
<li class="chapter" data-level="10.2" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#find-stationary"><i class="fa fa-check"></i><b>10.2</b> Finding a stationary distribution</a></li>
<li class="chapter" data-level="10.3" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#exist-unique"><i class="fa fa-check"></i><b>10.3</b> Existence and uniqueness</a></li>
<li class="chapter" data-level="10.4" data-path="S10-stationary-distributions.html"><a href="S10-stationary-distributions.html#stat-proof"><i class="fa fa-check"></i><b>10.4</b> Proof of existence and uniqueness</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem sheet 5</a></li>
<li class="chapter" data-level="11" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html"><i class="fa fa-check"></i><b>11</b> Long-term behaviour of Markov chains</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#equilibrium"><i class="fa fa-check"></i><b>11.1</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="11.2" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#convergence-examples"><i class="fa fa-check"></i><b>11.2</b> Examples of convergence and non-convergence</a></li>
<li class="chapter" data-level="11.3" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-ergodic"><i class="fa fa-check"></i><b>11.3</b> Ergodic theorem</a></li>
<li class="chapter" data-level="11.4" data-path="S11-long-term-chains.html"><a href="S11-long-term-chains.html#S11-proofs"><i class="fa fa-check"></i><b>11.4</b> Proofs of the limit and ergodic theorems</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S12-revision-i.html"><a href="S12-revision-i.html"><i class="fa fa-check"></i><b>12</b> End of of Part I: Discrete time Markov chains</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-revision-i.html"><a href="S12-revision-i.html#todo-revision"><i class="fa fa-check"></i><b>12.1</b> Things to do</a></li>
<li class="chapter" data-level="12.2" data-path="S12-revision-i.html"><a href="S12-revision-i.html#summary-i"><i class="fa fa-check"></i><b>12.2</b> Summary of Part I</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P06.html"><a href="P06.html"><i class="fa fa-check"></i>Problem sheet 6</a></li>
<li class="chapter" data-level="" data-path="A3.html"><a href="A3.html"><i class="fa fa-check"></i>Assessment 3</a></li>
<li class="part"><span><b>Part II: Continuous time Markov jump processes</b></span></li>
<li class="chapter" data-level="13" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html"><i class="fa fa-check"></i><b>13</b> Poisson process with Poisson increments</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-dist"><i class="fa fa-check"></i><b>13.1</b> Poisson distribution</a></li>
<li class="chapter" data-level="13.2" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#poisson-def-poisson"><i class="fa fa-check"></i><b>13.2</b> Definition 1: Poisson increments</a></li>
<li class="chapter" data-level="13.3" data-path="S13-poisson-poisson.html"><a href="S13-poisson-poisson.html#summed-marked"><i class="fa fa-check"></i><b>13.3</b> Summed and marked Poisson processes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html"><i class="fa fa-check"></i><b>14</b> Poisson process with exponential holding times</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#exponential"><i class="fa fa-check"></i><b>14.1</b> Exponential distribution</a></li>
<li class="chapter" data-level="14.2" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#definition-2-exponential-holding-times"><i class="fa fa-check"></i><b>14.2</b> Definition 2: exponential holding times</a></li>
<li class="chapter" data-level="14.3" data-path="S14-poisson-exponential.html"><a href="S14-poisson-exponential.html#cont-markov"><i class="fa fa-check"></i><b>14.3</b> Markov property in continuous time</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P07.html"><a href="P07.html"><i class="fa fa-check"></i>Problem sheet 7</a></li>
<li class="chapter" data-level="15" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html"><i class="fa fa-check"></i><b>15</b> Poisson process in infinitesimal time periods</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#infinitesimal"><i class="fa fa-check"></i><b>15.1</b> Definition 3: increments in infinitesimal time</a></li>
<li class="chapter" data-level="15.2" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#sum2"><i class="fa fa-check"></i><b>15.2</b> Example: sum of two Poisson processes</a></li>
<li class="chapter" data-level="15.3" data-path="S15-poisson-infinitesimal.html"><a href="S15-poisson-infinitesimal.html#forward"><i class="fa fa-check"></i><b>15.3</b> Forward equations and proof of equivalence</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html"><i class="fa fa-check"></i><b>16</b> Counting processes</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html#birth-processes"><i class="fa fa-check"></i><b>16.1</b> Birth processes</a></li>
<li class="chapter" data-level="16.2" data-path="S16-counting-processes.html"><a href="S16-counting-processes.html#TIPP"><i class="fa fa-check"></i><b>16.2</b> Time inhomogeneous Poisson process</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P08.html"><a href="P08.html"><i class="fa fa-check"></i>Problem Sheet 8</a></li>
<li class="chapter" data-level="17" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html"><i class="fa fa-check"></i><b>17</b> Continuous time Markov jump processes</a>
<ul>
<li class="chapter" data-level="17.1" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#jump-holding"><i class="fa fa-check"></i><b>17.1</b> Jump chain and holding times</a></li>
<li class="chapter" data-level="17.2" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#CTMC-examples"><i class="fa fa-check"></i><b>17.2</b> Examples</a></li>
<li class="chapter" data-level="17.3" data-path="S17-continuous-time.html"><a href="S17-continuous-time.html#explosion"><i class="fa fa-check"></i><b>17.3</b> A brief note on explosion</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html"><i class="fa fa-check"></i><b>18</b> Forward and backward equations</a>
<ul>
<li class="chapter" data-level="18.1" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#jump-infinitesimal"><i class="fa fa-check"></i><b>18.1</b> Transitions in infinitesimal time periods</a></li>
<li class="chapter" data-level="18.2" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#semigroup"><i class="fa fa-check"></i><b>18.2</b> Transition semigroup and the forward and backward equations</a></li>
<li class="chapter" data-level="18.3" data-path="S18-forward-backward.html"><a href="S18-forward-backward.html#matrix-exp"><i class="fa fa-check"></i><b>18.3</b> Matrix exponential</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P09.html"><a href="P09.html"><i class="fa fa-check"></i>Problem Sheet 9</a></li>
<li class="chapter" data-level="19" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html"><i class="fa fa-check"></i><b>19</b> Class structure and hitting times</a>
<ul>
<li class="chapter" data-level="19.1" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#classes-cont"><i class="fa fa-check"></i><b>19.1</b> Communicating classes</a></li>
<li class="chapter" data-level="19.2" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#periods2"><i class="fa fa-check"></i><b>19.2</b> A brief note on periodicity</a></li>
<li class="chapter" data-level="19.3" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#hitting2"><i class="fa fa-check"></i><b>19.3</b> Hitting probabilities and expected hitting times</a></li>
<li class="chapter" data-level="19.4" data-path="S19-class-hitting.html"><a href="S19-class-hitting.html#recurrence-transience2"><i class="fa fa-check"></i><b>19.4</b> Recurrence and transience</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html"><i class="fa fa-check"></i><b>20</b> Long-term behaviour of Markov jump processes</a>
<ul>
<li class="chapter" data-level="20.1" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#stationary-jump"><i class="fa fa-check"></i><b>20.1</b> Stationary distributions</a></li>
<li class="chapter" data-level="20.2" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#convergernce-cont"><i class="fa fa-check"></i><b>20.2</b> Convergence to equilibrium</a></li>
<li class="chapter" data-level="20.3" data-path="S20-long-term-jump.html"><a href="S20-long-term-jump.html#ergodic-cont"><i class="fa fa-check"></i><b>20.3</b> Ergodic theorem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P10.html"><a href="P10.html"><i class="fa fa-check"></i>Problem Sheet 10</a></li>
<li class="chapter" data-level="" data-path="A4.html"><a href="A4.html"><i class="fa fa-check"></i>Assessment 4</a></li>
<li class="chapter" data-level="21" data-path="S21-queues.html"><a href="S21-queues.html"><i class="fa fa-check"></i><b>21</b> Queues</a>
<ul>
<li class="chapter" data-level="21.1" data-path="S21-queues.html"><a href="S21-queues.html#MMinf"><i class="fa fa-check"></i><b>21.1</b> M/M/∞ infinite server process</a></li>
<li class="chapter" data-level="21.2" data-path="S21-queues.html"><a href="S21-queues.html#MM1"><i class="fa fa-check"></i><b>21.2</b> M/M/1 single server queue</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="S22-end.html"><a href="S22-end.html"><i class="fa fa-check"></i><b>22</b> End of Part II: Continuous time Markov jump processes</a>
<ul>
<li class="chapter" data-level="22.1" data-path="S22-end.html"><a href="S22-end.html#summary-ii"><i class="fa fa-check"></i><b>22.1</b> Summary of Part II</a></li>
<li class="chapter" data-level="22.2" data-path="S22-end.html"><a href="S22-end.html#exam-faqs"><i class="fa fa-check"></i><b>22.2</b> Exam FAQs</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P11.html"><a href="P11.html"><i class="fa fa-check"></i>Problem Sheet 11</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html"><i class="fa fa-check"></i>Computational worksheets</a>
<ul>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#C-about"><i class="fa fa-check"></i>About the computational worksheets</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#R-access"><i class="fa fa-check"></i>How to access R</a></li>
<li class="chapter" data-level="" data-path="computing.html"><a href="computing.html#R-background"><i class="fa fa-check"></i>R background</a></li>
</ul></li>
<li class="divider"></li>
<li></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2750 Introduction to Markov Processes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S11-long-term-chains" class="section level1" number="11">
<h1><span class="header-section-number">Section 11</span> Long-term behaviour of Markov chains</h1>
<div class="mysummary">
<ul>
<li>The limit theorem: convergence to the stationary distribution for irreducible, aperiodic, positive recurrent Markov chains</li>
<li>The ergodic theorem for the long-run proportion of time spent in each state</li>
</ul>
</div>
<div id="equilibrium" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Convergence to equilibrium</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/8ptEqJn99rU">
</iframe>
</div>
</div>
<p>In this section we’re interested in what happens to a Markov chain <span class="math inline">\((X_n)\)</span> in the long-run – that is, when <span class="math inline">\(n\)</span> tends to infinity.</p>
<p>One thing that <em>could</em> happen over time is that the distribution <span class="math inline">\(\mathbb P(X_n = i)\)</span> of the Markov chain could gradually settle down towards some “equilibrium” distribution. Further, perhaps that long-term equilibrium might not depend on the initial distribution, but the effects of the initial distribution might eventually almost disappear, exhibiting a “lack of memory” of the start of the process.</p>
<p>Just in case that does happen, let’s give it a name.</p>
<div class="definition">
<p><span id="def:eq-dist" class="definition"><strong>Definition 11.1  </strong></span>Let <span class="math inline">\((X_n)\)</span> be a Markov chain on a state space <span class="math inline">\(\mathcal S\)</span> with transition matrix <span class="math inline">\(\mathsf P\)</span>. Suppose there exists a distribution <span class="math inline">\(\mathbf p^* = (p_i^*)\)</span> on <span class="math inline">\(\mathcal S\)</span> (so <span class="math inline">\(p_i^* \geq 0\)</span> and <span class="math inline">\(\sum_i p_i^* = 1\)</span>) such that, whatever the initial distribution <span class="math inline">\(\boldsymbol\lambda = (\lambda_i)\)</span>, we have <span class="math inline">\(\mathbb P(X_n = j) \to p^*_j\)</span> as <span class="math inline">\(n \to \infty\)</span> for all <span class="math inline">\(j \in \mathcal S\)</span>. Then we say that <span class="math inline">\(\mathbf p^*\)</span> is an <strong>equilibrium distribution</strong>.</p>
</div>
<p>It’s clear there can only be at most one equilibrium distribution – but will there be one at all? The following is the most important result in this course. (Recall that an irreducible Markov chain is aperiodic if it has period 1.)</p>
<div class="theorem">
<p><span id="thm:limit" class="theorem"><strong>Theorem 11.1  (Limit theorem) </strong></span>Let <span class="math inline">\((X_n)\)</span> be an irreducible and aperiodic Markov chain. Then for any initial distribution <span class="math inline">\(\boldsymbol\lambda\)</span>, we have that <span class="math inline">\(\mathbb P(X_n = j) \to 1/\mu_j\)</span> as <span class="math inline">\(n \to \infty\)</span>, where <span class="math inline">\(\mu_j\)</span> is the expected return time to state <span class="math inline">\(j\)</span>.</p>
<p>In particular:</p>
<ul>
<li>Suppose <span class="math inline">\((X_n)\)</span> is positive recurrent. Then the unique stationary distribution <span class="math inline">\(\boldsymbol\pi\)</span> given by <span class="math inline">\(\pi_j = 1/\mu_j\)</span> is the equilibrium distribution, so <span class="math inline">\(\mathbb P(X_n = j) \to \pi_j\)</span> for all <span class="math inline">\(j\)</span>.</li>
<li>Suppose <span class="math inline">\((X_n)\)</span> is null recurrent or transient. Then <span class="math inline">\(\mathbb P(X_n = j) \to 0\)</span> for all <span class="math inline">\(j\)</span>, and there is no equilibrium distribution.</li>
</ul>
</div>
<p>I particularly like how this one theorem gathers together all the ideas from the course in one result (Markov chains, irreducibility, periodicity, recurrence/transience, positive/null recurrence, return times, stationary distribution…).</p>
<p>Note the three conditions for convergence to an equilibrium distribution: irreducibility, aperiodicity, and positive recurrence.</p>
<p>Consider a irreducible, aperiodic, positive recurrent Markov chain. Taking the initial distribution to be starting in state <span class="math inline">\(i\)</span> with certainty, the limit theorem tells us that <span class="math inline">\(p_{ij}(n) \to \pi_j\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. This means that the <span class="math inline">\(n\)</span>-step transition matrix will have the limiting value
<span class="math display">\[ \lim_{n \to \infty} \mathsf P(n) = \begin{pmatrix}
     \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N \\
     \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N \\
     \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
     \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N \end{pmatrix} , \]</span>
where each row is identical.</p>
<p>We give an <a href="S11-long-term-chains.html#S11-proofs">full proof of the limit theorem</a> below (optional and nonexaminable). However, this easier result gets part way there.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-15" class="theorem"><strong>Theorem 11.2  </strong></span>If an equilibrium distribution <span class="math inline">\(\mathbf p^*\)</span> does exist, then <span class="math inline">\(\mathbf p^*\)</span> is a stationary distribution.</p>
</div>
<p>Given this result it’s clear that an irreducible Markov chain cannot have an equilibrium distribution if it is null recurrent or transient, as it doesn’t even have a stationary distribution. So the positive recurrent case is the hard (nonexaminable) one.</p>
<div class="proof">
<p><span id="unlabeled-div-16" class="proof"><em>Proof</em>. </span>We need to verify that <span class="math inline">\(\mathbf p^* \mathsf P = \mathbf p^*\)</span>. We have
<span class="math display">\[ \sum_i p_i^* p_{ij} = \sum_i \left(\lim_{n\to\infty} p_{ki}(n) \right) p_{ij} = \lim_{n\to\infty} \sum_i p_{ki}(n) p_{ij} = \lim_{n\to\infty} p_{kj}(n+1) = p^*_j , \]</span>
as desired.</p>
</div>
<p>(Strictly speaking, swapping the sum and the limit is only formally justified when the state space is finite, although the theorem is true universally.)</p>
</div>
<div id="convergence-examples" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Examples of convergence and non-convergence</h2>
<div class="example">
<p><span id="exm:conv1" class="example"><strong>Example 11.1  </strong></span>The <a href="S05-markov-chains.html#S05-example">two-state “broken printer” Markov chain</a> is irreducible, aperiodic, and positive recurrent, so its stationary distribution is also the equilibrium distribution. We proved this from first principles in <a href="P03.html#P03">Question 3 on Problem Sheet 3</a>.</p>
</div>
<div class="example">
<p><span id="exm:conv2" class="example"><strong>Example 11.2  </strong></span>Recall <a href="S06-examples.html#S06-example1">the simple no-claims discount Markov chain from Lecture 6</a>, which is irreducible, aperiodic, and positive recurrent. We saw last time that is has the unique stationary distribution
<span class="math display">\[ \boldsymbol\pi = \left(\tfrac1{13} \quad \tfrac{3}{13}\quad \tfrac9{13}\right) = (0.0769\quad 0.2308\quad 0.6923) . \]</span></p>
<p>From the limit theorem, we see that the <span class="math inline">\(n\)</span>-step transition probability tends to a limit where every row is equal to <span class="math inline">\(\boldsymbol\pi\)</span>. We can check using a computer: for <span class="math inline">\(n = 12\)</span>, say,
<span class="math display">\[ \mathsf P(12) = \mathsf P^{12} = \begin{pmatrix} 0.0770 &amp; 0.2308 &amp; 0.6923 \\ 0.0769 &amp; 0.2308 &amp; 0.6923 \\ 0.0769 &amp; 0.2308 &amp; 0.6923 \end{pmatrix}, \]</span>
where <span class="math inline">\(p_{ij}(12)\)</span> is equal to <span class="math inline">\(\pi_j\)</span> up to at least 3 decimal places for all <span class="math inline">\(i,j\)</span>. As <span class="math inline">\(n\)</span> gets bigger, the matrix gets closer and closer to the limiting form.</p>
</div>
<div class="example">
<p><span id="exm:conv-rw" class="example"><strong>Example 11.3  </strong></span>The simple random walk is null recurrent for <span class="math inline">\(p = \frac12\)</span> and transient otherwise. Either way, we have <span class="math inline">\(\mathbb P(X_n = i) \to 0\)</span> for all states <span class="math inline">\(i\)</span>, and there is no equilibrium distribution.</p>
</div>
<div class="example">
<p><span id="exm:conv4" class="example"><strong>Example 11.4  </strong></span>Consider a Markov chain <span class="math inline">\((X_n)\)</span> on state space <span class="math inline">\(\mathcal S = \{0,1\}\)</span> and transition matrix
<span class="math display">\[ \mathsf P = \begin{pmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{pmatrix} . \]</span>
So at each stage we swap from state <span class="math inline">\(0\)</span> to state <span class="math inline">\(1\)</span> and back again. This chain is irreducible and positive recurrent, so it has a unique stationary distribution, which is clearly <span class="math inline">\(\boldsymbol\pi = (\frac12\quad\frac12)\)</span>.</p>
<p>However, we don’t have convergence to equilibrium. If we start from initial distribution <span class="math inline">\((\lambda_0, \lambda_1)\)</span>, then <span class="math inline">\(\mathbb P(X_n = 0) = \lambda_0\)</span> for even <span class="math inline">\(n\)</span> and <span class="math inline">\(\mathbb P(X_n = 0) = \lambda_1\)</span> for odd <span class="math inline">\(n\)</span>. When <span class="math inline">\(\lambda_0 \neq \frac12\)</span>, this does not converge.</p>
<p>The point is that this chain is <em>not</em> aperiodic: it has period <span class="math inline">\(2\)</span>, so the limit theorem does not apply.</p>
</div>
<div class="example">
<p><span id="exm:conv5" class="example"><strong>Example 11.5  </strong></span>Consider a Markov chain with state space <span class="math inline">\(\mathcal S = \{1,2,3\}\)</span> and transition diagram as shown below.</p>
<div class="figure" style="text-align: center"><span id="fig:stat-ex"></span>
<img src="math2750_files/figure-html/stat-ex-1.png" alt="Transition diagram for a Markov chain with two positive recurrent classes." width="480" />
<p class="caption">
Figure 11.1: Transition diagram for a Markov chain with two positive recurrent classes.
</p>
</div>
<p>This chain is not irreducible, but has two aperiodic and positive recurrent communicating classes. In particular, it has many stationary distributions including <span class="math inline">\((1, 0, 0)\)</span> and <span class="math inline">\((0, \frac8{17}, \frac9{17})\)</span> (optional exercise for the reader). If we start in state 1, then the limiting distribution is the former, while if we start in states 2 or 3, the limiting distribution is the latter.</p>
<p>In particular, as <span class="math inline">\(n \to \infty\)</span>, we have
<span class="math display">\[ \mathsf P^{(n)} \to \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; \frac8{17} &amp; \frac9{17} \\ 0 &amp; \frac8{17} &amp; \frac9{17} \end{pmatrix}. \]</span></p>
</div>
</div>
<div id="S11-ergodic" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Ergodic theorem</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/Pg7sR0wJ3vo">
</iframe>
</div>
</div>
<p>The limit theorem looked at the limit of <span class="math inline">\(\mathbb P(X_n = j)\)</span>, the probability that the Markov chain is in state <span class="math inline">\(j\)</span> at some specific point in time <span class="math inline">\(n\)</span> a long time in the future. We could also look at the <em>long-run amount of time</em> spent in state <span class="math inline">\(j\)</span>; that is, averaging the behaviour over a long time period. (The word “ergodic” is used in mathematics to refer to concepts to do with the long-term proportion of time.)</p>
<p>Let us write
<span class="math display">\[ V_j(N) := \# \big\{ n &lt; N : X_n = j \} \]</span>
for the total number of visits to state <span class="math inline">\(j\)</span> up to time <span class="math inline">\(N\)</span>. Then we can interpret <span class="math inline">\(V_j(n)/n\)</span> as the proportion of time up to time <span class="math inline">\(n\)</span> spent in state <span class="math inline">\(j\)</span>, and its limiting value (if it exists) to be the <strong>long-run proportion of time</strong> spent in state <span class="math inline">\(j\)</span>.</p>
<div class="theorem">
<p><span id="thm:ergodic" class="theorem"><strong>Theorem 11.3  (Ergodic theorem) </strong></span>Let <span class="math inline">\((X_n)\)</span> be an irreducible Markov chain. Then for any initial distribution <span class="math inline">\(\boldsymbol\lambda\)</span> we have that <span class="math inline">\(V_j(n)/n \to 1/\mu_j\)</span> almost surely as <span class="math inline">\(n \to \infty\)</span>, where <span class="math inline">\(\mu_j\)</span> is the expected return time to state <span class="math inline">\(j\)</span>.</p>
<p>In particular:</p>
<ul>
<li>Suppose <span class="math inline">\((X_n)\)</span> is positive recurrent. Then there is a unique stationary distribution <span class="math inline">\(\boldsymbol\pi\)</span> given by <span class="math inline">\(\pi_j = 1/\mu_j\)</span>, and <span class="math inline">\(V_j(n)/n \to \pi_j\)</span> almost surely for all <span class="math inline">\(j\)</span>.</li>
<li>Suppose <span class="math inline">\((X_n)\)</span> is null recurrent or transient. Then <span class="math inline">\(V_j(n)/n \to 0\)</span> almost surely for all <span class="math inline">\(j\)</span>.</li>
</ul>
</div>
<p>For completeness, we should note that “almost sure” convergence means that <span class="math inline">\(\mathbb P(V_j(n)/n \to 1/\mu_j) = 1\)</span>, although the precise definition is not important for us in this module.</p>
<p>Note that, because we are averaging over a long-time period, we no longer need the condition that the Markov chain is aperiodic; for convergence of the long-term proportion of time to the stationary distribution we just need irreducibility and positive recurrence.</p>
<p>Again, we give an optional and nonexaminable proof <a href="S11-long-term-chains.html#S11-proofs">below</a>.</p>
<div class="example">
<p><span id="exm:ergodic-ex" class="example"><strong>Example 11.6  </strong></span>Recall <a href="S06-examples.html#S06-example1">the simple no-claims discount Markov chain</a>. Since this chain is irreducible and positive recurrent, we now see that the long-term proportion of time spent in each state corresponds to the stationary distribution <span class="math inline">\(\boldsymbol\pi = (\frac1{13} \quad \frac{3}{13}\quad \frac9{13})\)</span>. Therefore, over the lifetime of an insurance policy held for a long period of time, the average discount is approximately
<span class="math display">\[ \tfrac{1}{13}(0\%) + \tfrac{3}{13}(25\%) + \tfrac{9}{13}(50\%) = \tfrac{21}{52} = 40.4\% . \]</span></p>
</div>
<div class="example">
<p><span id="exm:ergodic-ex2" class="example"><strong>Example 11.7  </strong></span>The two-state “swapping” chain we saw earlier did have a unique stationary distribution <span class="math inline">\((\frac12, \frac12)\)</span>, but did not have an equilibrium distribution, because it was periodic. But it is true that <span class="math inline">\(V_0(n)/n \to \pi_0 = \frac12\)</span> and <span class="math inline">\(V_1(n)/n \to \pi_1 = \frac12\)</span>, due to the ergodic theorem. So although where we are at some specific point in the future depends on where we started from, in the long run we always spend half our time in each state.</p>
</div>
</div>
<div id="S11-proofs" class="section level2" number="11.4">
<h2><span class="header-section-number">11.4</span> Proofs of the limit and ergodic theorems</h2>
<div class="mysummary">
<p><em>This subsection is optional and nonexaminable.</em></p>
</div>
<p>Again, it’s important to be able to use the limit and ergodic theorems, but less important to be able to prove them.</p>
<p>First, the limit theorem. The only bit left is the first part: that for an irreducible, aperiodic, positive recurrent Markov chain, the stationary distribution <span class="math inline">\(\boldsymbol\pi\)</span> is an equilibrium distribution.</p>
<p>This cunning proof uses a technique called “coupling”. When looking at two different random objects <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (like random variables or stochastic processes), it seems natural to prefer <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to be independent. However, <strong>coupling</strong> is the idea that it can sometimes be beneficial to let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> actually be dependent on each other.</p>
<div class="proof">
<p><span id="unlabeled-div-17" class="proof"><em>Proof</em> (Proof of Theorem <a href="S11-long-term-chains.html#thm:limit">11.1</a>). </span>Let <span class="math inline">\((X_n)\)</span> be our irreducible, aperiodic, positive recurrent Markov chain with transition matrix <span class="math inline">\(\mathsf P\)</span> and initial distribution <span class="math inline">\(\boldsymbol\lambda\)</span>. Let <span class="math inline">\((Y_n)\)</span> be a Markov chain also with transition matrix <span class="math inline">\(\mathsf P\)</span> but “in equilibrium” – that is, started from the stationary distribution <span class="math inline">\(\boldsymbol\pi\)</span>, and thus staying in that distribution for ever.</p>
<p>Pick a state <span class="math inline">\(s \in \mathcal S\)</span>, and let <span class="math inline">\(T\)</span> be the first time the <span class="math inline">\(X_n = Y_n = s\)</span> (or <span class="math inline">\(T = \infty\)</span>, if that never happens). Now here’s the coupling: after <span class="math inline">\(T\)</span>, when <span class="math inline">\((X_n)\)</span> and <span class="math inline">\((Y_n)\)</span> collide at <span class="math inline">\(s\)</span>, then make <span class="math inline">\((X_n)\)</span> stick to <span class="math inline">\((Y_n)\)</span>, so <span class="math inline">\(X_n = Y_n\)</span> for <span class="math inline">\(n \geq T\)</span>. Since a Markov chain has no memory, <span class="math inline">\((X_{T+n}) = (Y_{T+n})\)</span> is still just a Markov chain with the same transition probabilities from that point on. (Readers of <a href="S09-recurrence-transience.html#S09-strong-markov">a previous optional subsection</a> will recognise <span class="math inline">\(T\)</span> as a stopping time and will notice we’re using the strong Markov property.) Most importantly, thanks to the coupling, from the time <span class="math inline">\(T\)</span> onwards, <span class="math inline">\((X_n)\)</span> will also always have distribution <span class="math inline">\(\boldsymbol\pi\)</span>, a fact that will obviously be very useful in this proof.</p>
<p>It will be important that <span class="math inline">\(T\)</span> is finite with probability 1. Define <span class="math inline">\((\mathbf Z_n)\)</span> by <span class="math inline">\(\mathbf Z_n = (X_n, Y_n)\)</span>. So <span class="math inline">\((\mathbf Z_n)\)</span> is a Markov chain on <span class="math inline">\(\mathcal S \times \mathcal S\)</span>, and <span class="math inline">\(T\)</span> is the expected hitting time of <span class="math inline">\((\mathbf Z_n)\)</span> to the state <span class="math inline">\((s, s) \in \mathcal S \times \mathcal S\)</span>. The transition probabilities for <span class="math inline">\((\mathbf Z_n)\)</span> are <span class="math inline">\(\mathsf{\tilde P} = (\tilde p_{(i,k)(j,l)})\)</span> where
<span class="math display">\[ \tilde p_{(i,k)(j,l)} = p_{ij}p_{kl} . \]</span>
This is the probability that the joint chain goes from <span class="math inline">\(\mathbf Z_n = (X_n, Y_n) = (i, k)\)</span> to <span class="math inline">\(\mathbf Z_{n+1} = (X_{n+1}, Y_{n+1}) = (j, l)\)</span>.</p>
<p>Since the original Markov chain is irreducible and aperiodic, this means that <span class="math inline">\(p_{ij}(n), p_{kl}(n) &gt; 0\)</span> for all <span class="math inline">\(n\)</span> sufficiently large, so <span class="math inline">\(\tilde p_{(i,k)(j,l)}(n) &gt; 0\)</span> for all <span class="math inline">\(n\)</span> sufficiently large also, meaning that <span class="math inline">\((\mathbf Z_n)\)</span> is irreducible (and, although this isn’t required, aperiodic). Further, <span class="math inline">\((\mathbf Z_n)\)</span> has a stationary distribution <span class="math inline">\(\mathbf{\tilde \pi} = (\tilde \pi_{(i,k)})\)</span> where
<span class="math display">\[ \tilde \pi_{(i,k)} = \pi_i \pi_k , \]</span>
which means that <span class="math inline">\((\mathbf Z_n)\)</span> is positive recurrent. Thus <span class="math inline">\(T\)</span> is finite with probability 1.</p>
<p>So we can finally prove the limit theorem. We want to show that <span class="math inline">\(\mathbb P(X_n = i)\)</span> tends to <span class="math inline">\(\pi_i\)</span>. The difference between them is
<span class="math display">\[\begin{align*}
\big|\mathbb P(X_i = i) - \pi_i\big|
&amp;= \mathbb P(n \leq T)\times\big|\mathbb P(X_i = i \mid n \leq T) - \pi_i\big|  + P(n &gt; T) \times |\pi_i - \pi_i| \\
&amp;= \mathbb P(n \leq T)\times\big|\mathbb P(X_i = i \mid n \leq T) \\
&amp;\leq \mathbb P(n \leq T) .
\end{align*}\]</span>
Here, the equality on the first line is because <span class="math inline">\((X_n)\)</span> follows the stationary distribution exactly once it sticks to <span class="math inline">\((Y_n)\)</span> after time <span class="math inline">\(T\)</span>, and the inequality on the third line is because the absolute difference between two probabilities is between 0 and 1. But we’ve already shown that <span class="math inline">\(T\)</span> is finite with probability 1, so <span class="math inline">\(\mathbb P(n \leq T) = \mathbb P(T \geq n) \to 0\)</span>, and we’re done.</p>
</div>
<p>The proof of the ergodic theorem uses the law of large numbers. Recall that the law of large numbers states that if <span class="math inline">\(Y_1, Y_2, \dots\)</span> are IID random variables with mean <span class="math inline">\(\mu\)</span>, then
<span class="math display">\[ \frac{Y_1 + Y_2 + \cdots + Y_n}{n} \to \mu \qquad \text{as $n \to \infty$}. \]</span>
This means it’s also true that for any sequence <span class="math inline">\((a_n)\)</span> with <span class="math inline">\(a_n \to \infty\)</span>, we also have
<span class="math display">\[ \frac{Y_1 + Y_2 + \cdots + Y_{a_n}}{a_n} \to \mu \qquad \text{as $n \to \infty$}. \]</span></p>
<div class="proof">
<p><span id="unlabeled-div-18" class="proof"><em>Proof</em> (Proof of Theorem <a href="S11-long-term-chains.html#thm:ergodic">11.3</a>). </span>If <span class="math inline">\((X_n)\)</span> is transient, then the number of visits to state <span class="math inline">\(i\)</span> is finite with probability 1, so <span class="math inline">\(V_i(n)/n \to 0\)</span>, as required.</p>
<p>Suppose instead that <span class="math inline">\((X_n)\)</span> is recurrent. By our <a href="S09-recurrence-transience.html#S09-lemma">useful lemma</a> we know we will hit <span class="math inline">\(i\)</span> in finite time, so we can ignore that negligible “burn-in” period, and (by the strong Markov property) assume we start from <span class="math inline">\(i\)</span>. Let <span class="math inline">\(M_{i}^{(r)}\)</span> be the time between the <span class="math inline">\(r\)</span>th and <span class="math inline">\((r+1)\)</span>th visits to <span class="math inline">\(i\)</span>. Note that the <span class="math inline">\(M_{i}^{(r)}\)</span> are IID with mean <span class="math inline">\(\mu_i\)</span>.</p>
<p>The time of the last visit to <span class="math inline">\(i\)</span> before time <span class="math inline">\(n\)</span> is
<span class="math display">\[ M_{i}^{(1)} + M_{i}^{(2)} + \cdots + M_{i}^{(V_i(n)-1)} &lt; n ,\]</span>
and the time of the first visit to <span class="math inline">\(i\)</span> after time <span class="math inline">\(n\)</span> is
<span class="math display">\[ M_{i}^{(1)} + M_{i}^{(2)} + \cdots + M_{i}^{(V_i(n))} \geq n .\]</span>
Hence
<span class="math display" id="eq:erg">\[\begin{equation}
\frac{M_{i}^{(1)} + M_{i}^{(2)} + \cdots + M_{i}^{(V_i(n)-1)}}{V_i(n)} &lt; \frac{n}{V_i(n)} \leq \frac{M_{i}^{(1)} + M_{i}^{(2)} + \cdots + M_{i}^{(V_i(n))}}{V_i(n)} . \tag{11.1}
\end{equation}\]</span></p>
<p>Because <span class="math inline">\((X_n)\)</span> is recurrent, we keep returning to <span class="math inline">\(i\)</span>, so <span class="math inline">\(V_i(n) \to \infty\)</span> with probability 1. Hence, by the law of large numbers, both the left- and right-hand sides of <a href="S11-long-term-chains.html#eq:erg">(11.1)</a> tend to <span class="math inline">\(\mathbb E M_{i}^{(r)} = \mu_i\)</span>. So <span class="math inline">\(n/V_i(n)\)</span> is sandwiched between them, and tends to <span class="math inline">\(\mu_i\)</span> too. Finally <span class="math inline">\(n/V_i(n) \to \mu_i\)</span> is equivalent to <span class="math inline">\(V_i(n)/n \to 1/\mu_i\)</span>, so we are done.</p>
</div>
<div class="mysummary">
<p>This completes the material on discrete time Markov chains. <strong>In the next section</strong>, we recap what we have learned, and have a little time for some revision.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="P05.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="S12-revision-i.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math2750.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
